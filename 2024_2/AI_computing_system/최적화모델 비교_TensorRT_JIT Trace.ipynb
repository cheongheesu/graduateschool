{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 숙제 1"
      ],
      "metadata": {
        "id": "KsYTOwFWELOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch-tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bt9y1hcxD4jd",
        "outputId": "c09a29ff-5939-4e90-fe0e-ed43551b5e6c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-tensorrt in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: torch<2.6.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (2.5.0+cu121)\n",
            "Requirement already satisfied: tensorrt-cu12==10.3.0 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (10.3.0)\n",
            "Requirement already satisfied: tensorrt-cu12-bindings==10.3.0 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (10.3.0)\n",
            "Requirement already satisfied: tensorrt-cu12-libs==10.3.0 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (10.3.0)\n",
            "Requirement already satisfied: packaging>=23 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.10/dist-packages (from tensorrt-cu12-libs==10.3.0->torch-tensorrt) (12.6.77)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.6.0,>=2.5.0->torch-tensorrt) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.6.0,>=2.5.0->torch-tensorrt) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.6.0,>=2.5.0->torch-tensorrt) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.6.0,>=2.5.0->torch-tensorrt) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.6.0,>=2.5.0->torch-tensorrt) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<2.6.0,>=2.5.0->torch-tensorrt) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.6.0,>=2.5.0->torch-tensorrt) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/NVIDIA/TensorRT-Model-Optimizer.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "01C0hOFDI2Y-",
        "outputId": "978cd7f6-c41a-4e68-d21e-f2bd61a0f1cd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/NVIDIA/TensorRT-Model-Optimizer.git\n",
            "  Cloning https://github.com/NVIDIA/TensorRT-Model-Optimizer.git to /tmp/pip-req-build-373vdsfj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/NVIDIA/TensorRT-Model-Optimizer.git /tmp/pip-req-build-373vdsfj\n",
            "  Resolved https://github.com/NVIDIA/TensorRT-Model-Optimizer.git to commit 1574baaab3f3e34ffab2fa25439dd3f019aab512\n",
            "\u001b[31mERROR: git+https://github.com/NVIDIA/TensorRT-Model-Optimizer.git does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch_tensorrt"
      ],
      "metadata": {
        "id": "xjCI0i2XDWDu"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 데이터 로드 및 전처리"
      ],
      "metadata": {
        "id": "WjgmWGyhmoK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Eo3w3yOumqO2",
        "outputId": "bae8c980-4cac-4462-bb5e-993a54e4de50"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Alexnet 모델 정의 (PyTorch 사용)"
      ],
      "metadata": {
        "id": "vPehjz8anXEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features  = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.AdaptiveAvgPool2d((6, 6))\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Q4WbEcMypTnf"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 모델 학습 설정"
      ],
      "metadata": {
        "id": "Io3bOf81nqxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 모델 학습 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = AlexNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "hosUdWIXntUO"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 모델 학습"
      ],
      "metadata": {
        "id": "1kDV6HNjoifz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "patience = 2  # Early stopping patience\n",
        "best_loss = float('inf')\n",
        "stopping_step = 0\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 기존의 기울기 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 + 역전파 + 최적화\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 값 출력\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:    # 매 100 미니배치마다 출력\n",
        "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "        # Early stopping 조건 확인\n",
        "    if running_loss < best_loss:\n",
        "        best_loss = running_loss\n",
        "        stopping_step = 0\n",
        "    else:\n",
        "        stopping_step += 1\n",
        "        if stopping_step >= patience:\n",
        "            print('Early stopping triggered')\n",
        "            break\n",
        "\n",
        "print('학습 완료')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFPPlxt9ZPgx",
        "outputId": "64360fb0-2343-46be-c163-857ab989d61e",
        "collapsed": true
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 100] loss: 2.020\n",
            "[Epoch 1, Batch 200] loss: 1.657\n",
            "[Epoch 1, Batch 300] loss: 1.468\n",
            "[Epoch 2, Batch 100] loss: 1.229\n",
            "[Epoch 2, Batch 200] loss: 1.171\n",
            "[Epoch 2, Batch 300] loss: 1.118\n",
            "[Epoch 3, Batch 100] loss: 0.983\n",
            "[Epoch 3, Batch 200] loss: 0.950\n",
            "[Epoch 3, Batch 300] loss: 0.916\n",
            "[Epoch 4, Batch 100] loss: 0.792\n",
            "[Epoch 4, Batch 200] loss: 0.790\n",
            "[Epoch 4, Batch 300] loss: 0.793\n",
            "[Epoch 5, Batch 100] loss: 0.692\n",
            "[Epoch 5, Batch 200] loss: 0.694\n",
            "[Epoch 5, Batch 300] loss: 0.687\n",
            "[Epoch 6, Batch 100] loss: 0.594\n",
            "[Epoch 6, Batch 200] loss: 0.626\n",
            "[Epoch 6, Batch 300] loss: 0.614\n",
            "[Epoch 7, Batch 100] loss: 0.514\n",
            "[Epoch 7, Batch 200] loss: 0.539\n",
            "[Epoch 7, Batch 300] loss: 0.538\n",
            "[Epoch 8, Batch 100] loss: 0.429\n",
            "[Epoch 8, Batch 200] loss: 0.487\n",
            "[Epoch 8, Batch 300] loss: 0.499\n",
            "[Epoch 9, Batch 100] loss: 0.410\n",
            "[Epoch 9, Batch 200] loss: 0.428\n",
            "[Epoch 9, Batch 300] loss: 0.433\n",
            "[Epoch 10, Batch 100] loss: 0.346\n",
            "[Epoch 10, Batch 200] loss: 0.386\n",
            "[Epoch 10, Batch 300] loss: 0.406\n",
            "[Epoch 11, Batch 100] loss: 0.313\n",
            "[Epoch 11, Batch 200] loss: 0.352\n",
            "[Epoch 11, Batch 300] loss: 0.364\n",
            "[Epoch 12, Batch 100] loss: 0.279\n",
            "[Epoch 12, Batch 200] loss: 0.311\n",
            "[Epoch 12, Batch 300] loss: 0.341\n",
            "[Epoch 13, Batch 100] loss: 0.249\n",
            "[Epoch 13, Batch 200] loss: 0.282\n",
            "[Epoch 13, Batch 300] loss: 0.303\n",
            "[Epoch 14, Batch 100] loss: 0.238\n",
            "[Epoch 14, Batch 200] loss: 0.261\n",
            "[Epoch 14, Batch 300] loss: 0.270\n",
            "[Epoch 15, Batch 100] loss: 0.224\n",
            "[Epoch 15, Batch 200] loss: 0.259\n",
            "[Epoch 15, Batch 300] loss: 0.284\n",
            "[Epoch 16, Batch 100] loss: 0.200\n",
            "[Epoch 16, Batch 200] loss: 0.220\n",
            "[Epoch 16, Batch 300] loss: 0.251\n",
            "[Epoch 17, Batch 100] loss: 0.173\n",
            "[Epoch 17, Batch 200] loss: 0.209\n",
            "[Epoch 17, Batch 300] loss: 0.228\n",
            "[Epoch 18, Batch 100] loss: 0.180\n",
            "[Epoch 18, Batch 200] loss: 0.201\n",
            "[Epoch 18, Batch 300] loss: 0.226\n",
            "[Epoch 19, Batch 100] loss: 0.187\n",
            "[Epoch 19, Batch 200] loss: 0.188\n",
            "[Epoch 19, Batch 300] loss: 0.207\n",
            "[Epoch 20, Batch 100] loss: 0.156\n",
            "[Epoch 20, Batch 200] loss: 0.183\n",
            "[Epoch 20, Batch 300] loss: 0.223\n",
            "학습 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 모델 평가"
      ],
      "metadata": {
        "id": "MN2sBKQuttZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 테스트 정확도 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'최종 테스트 정확도: {100 * correct / total:.4f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjBZmFMnntN1",
        "outputId": "a580e017-3c89-44f1-8207-c2a310800c1f"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 테스트 정확도: 77.1100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 숙제2 (이어서)"
      ],
      "metadata": {
        "id": "yPLR8eObEHyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Torch-TensorRT 적용"
      ],
      "metadata": {
        "id": "fV-zJcxB-5al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 모드 설정\n",
        "model.eval().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JqRQ5rZODB1A",
        "outputId": "1fdf0e73-097d-4bb9-c046-3130c39e2ae5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (13): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Dropout(p=0.5, inplace=False)\n",
              "    (7): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch-TensorRT를 사용해 모델 최적화\n",
        "inputs = [torch.rand((1, 3, 32, 32)).to(device)]\n",
        "enabled_precisions = {torch.float}\n",
        "debug = True\n",
        "workspace_size = 20 << 30\n",
        "min_block_size = 7\n",
        "torch_executed_ops = {}\n",
        "\n",
        "optimized_model = torch_tensorrt.compile(\n",
        "    model,\n",
        "    ir=\"torch_compile\",\n",
        "    inputs=inputs,\n",
        "    enabled_precisions=enabled_precisions,\n",
        "    debug=debug,\n",
        "    workspace_size=workspace_size,\n",
        "    min_block_size=min_block_size,\n",
        "    torch_executed_ops=torch_executed_ops,\n",
        ")"
      ],
      "metadata": {
        "id": "7EpjR26ZCzBo"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference 속도 비교\n",
        "import time\n",
        "\n",
        "def measure_inference_time(model, inputs, num_tests=100):\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_tests):\n",
        "            try:\n",
        "                _ = model(*inputs)\n",
        "            except Exception as e:\n",
        "                print(f\"Error during inference: {e}\")\n",
        "                break\n",
        "    end_time = time.time()\n",
        "    return (end_time - start_time) / num_tests"
      ],
      "metadata": {
        "id": "oVIWj-HcLhLG"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 모델 Inference 시간 측정\n",
        "model.eval()\n",
        "original_time = measure_inference_time(model, inputs)\n",
        "print(f'기존 모델 평균 Inference 시간: {original_time:.6f} 초')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZEmVCMqCy8r",
        "outputId": "0cdf51e5-0b60-439f-fd83-eb9c9270fca4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기존 모델 평균 Inference 시간: 0.001826 초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch-TensorRT 최적화 모델 Inference 시간 측정\n",
        "optimized_time = measure_inference_time(optimized_model, inputs)\n",
        "print(f'Torch-TensorRT 최적화 모델 평균 Inference 시간: {optimized_time:.6f} 초')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzrhqEJeBKNv",
        "outputId": "8089fb53-c2aa-42a1-d5e3-e4ff26fb3a7f",
        "collapsed": true
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f16: 6>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, make_refittable=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False, timing_cache_path='/tmp/torch_tensorrt_engine_cache/timing_cache.bin', lazy_engine_init=False, cache_built_engines=False, reuse_cached_engines=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %l_self_modules_features_modules_0_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_0_parameters_weight_]\n",
            "    %l_self_modules_features_modules_0_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_0_parameters_bias_]\n",
            "    %l_x_ : torch.Tensor [num_users=1] = placeholder[target=L_x_]\n",
            "    %l_self_modules_features_modules_3_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_3_parameters_weight_]\n",
            "    %l_self_modules_features_modules_3_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_3_parameters_bias_]\n",
            "    %l_self_modules_features_modules_6_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_6_parameters_weight_]\n",
            "    %l_self_modules_features_modules_6_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_6_parameters_bias_]\n",
            "    %l_self_modules_features_modules_8_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_8_parameters_weight_]\n",
            "    %l_self_modules_features_modules_8_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_8_parameters_bias_]\n",
            "    %l_self_modules_features_modules_10_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_10_parameters_weight_]\n",
            "    %l_self_modules_features_modules_10_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_10_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_1_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_1_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_1_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_1_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_4_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_4_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_4_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_4_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_7_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_7_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_7_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_7_parameters_bias_]\n",
            "    %input_1 : [num_users=1] = call_function[target=torch.conv2d](args = (%l_x_, %l_self_modules_features_modules_0_parameters_weight_, %l_self_modules_features_modules_0_parameters_bias_, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_2 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_1,), kwargs = {inplace: True})\n",
            "    %input_3 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_2, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_4 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_3, %l_self_modules_features_modules_3_parameters_weight_, %l_self_modules_features_modules_3_parameters_bias_, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_5 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_4,), kwargs = {inplace: True})\n",
            "    %input_6 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_5, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_7 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_6, %l_self_modules_features_modules_6_parameters_weight_, %l_self_modules_features_modules_6_parameters_bias_, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_8 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_7,), kwargs = {inplace: True})\n",
            "    %input_9 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_8, %l_self_modules_features_modules_8_parameters_weight_, %l_self_modules_features_modules_8_parameters_bias_, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_10 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_9,), kwargs = {inplace: True})\n",
            "    %input_11 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_10, %l_self_modules_features_modules_10_parameters_weight_, %l_self_modules_features_modules_10_parameters_bias_, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_12 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_11,), kwargs = {inplace: True})\n",
            "    %input_13 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_12, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_14 : [num_users=1] = call_function[target=torch.nn.functional.adaptive_avg_pool2d](args = (%input_13, (6, 6)), kwargs = {})\n",
            "    %input_15 : [num_users=1] = call_method[target=flatten](args = (%input_14, 1, -1), kwargs = {})\n",
            "    %input_16 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_15, %l_self_modules_classifier_modules_1_parameters_weight_, %l_self_modules_classifier_modules_1_parameters_bias_), kwargs = {})\n",
            "    %input_17 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_16,), kwargs = {inplace: True})\n",
            "    %input_18 : [num_users=1] = call_function[target=torch.nn.functional.dropout](args = (%input_17, 0.5, False, False), kwargs = {})\n",
            "    %input_19 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_18, %l_self_modules_classifier_modules_4_parameters_weight_, %l_self_modules_classifier_modules_4_parameters_bias_), kwargs = {})\n",
            "    %input_20 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_19,), kwargs = {inplace: True})\n",
            "    %input_21 : [num_users=1] = call_function[target=torch.nn.functional.dropout](args = (%input_20, 0.5, False, False), kwargs = {})\n",
            "    %input_22 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_21, %l_self_modules_classifier_modules_7_parameters_weight_, %l_self_modules_classifier_modules_7_parameters_bias_), kwargs = {})\n",
            "    return (input_22,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %l_self_modules_features_modules_0_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_0_parameters_weight_]\n",
            "    %l_self_modules_features_modules_0_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_0_parameters_bias_]\n",
            "    %l_x_ : torch.Tensor [num_users=1] = placeholder[target=L_x_]\n",
            "    %l_self_modules_features_modules_3_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_3_parameters_weight_]\n",
            "    %l_self_modules_features_modules_3_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_3_parameters_bias_]\n",
            "    %l_self_modules_features_modules_6_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_6_parameters_weight_]\n",
            "    %l_self_modules_features_modules_6_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_6_parameters_bias_]\n",
            "    %l_self_modules_features_modules_8_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_8_parameters_weight_]\n",
            "    %l_self_modules_features_modules_8_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_8_parameters_bias_]\n",
            "    %l_self_modules_features_modules_10_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_10_parameters_weight_]\n",
            "    %l_self_modules_features_modules_10_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_10_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_1_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_1_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_1_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_1_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_4_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_4_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_4_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_4_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_7_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_7_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_7_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_7_parameters_bias_]\n",
            "    %clone_default_16 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_7_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_15 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_7_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_14 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_4_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_13 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_4_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_12 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_1_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_11 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_1_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_10 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_10_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_9 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_10_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_8 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_8_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_7 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_8_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_6 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_6_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_5 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_6_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_4 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_3_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_3 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_3_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_2 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_x_,), kwargs = {})\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_0_parameters_bias_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_0_parameters_weight_,), kwargs = {})\n",
            "    %input_1 : [num_users=1] = call_function[target=torch.conv2d](args = (%clone_default_2, %clone_default, %clone_default_1, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_2 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_1,), kwargs = {inplace: True})\n",
            "    %input_3 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_2, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_4 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_3, %clone_default_3, %clone_default_4, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_5 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_4,), kwargs = {inplace: True})\n",
            "    %input_6 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_5, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_7 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_6, %clone_default_5, %clone_default_6, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_8 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_7,), kwargs = {inplace: True})\n",
            "    %input_9 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_8, %clone_default_7, %clone_default_8, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_10 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_9,), kwargs = {inplace: True})\n",
            "    %input_11 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_10, %clone_default_9, %clone_default_10, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_12 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_11,), kwargs = {inplace: True})\n",
            "    %input_13 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_12, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_14 : [num_users=1] = call_function[target=torch.nn.functional.adaptive_avg_pool2d](args = (%input_13, (6, 6)), kwargs = {})\n",
            "    %input_15 : [num_users=1] = call_method[target=flatten](args = (%input_14, 1, -1), kwargs = {})\n",
            "    %input_16 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_15, %clone_default_11, %clone_default_12), kwargs = {})\n",
            "    %input_17 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_16,), kwargs = {inplace: True})\n",
            "    %input_18 : [num_users=1] = call_function[target=torch.nn.functional.dropout](args = (%input_17, 0.5, False, False), kwargs = {})\n",
            "    %input_19 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_18, %clone_default_13, %clone_default_14), kwargs = {})\n",
            "    %input_20 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_19,), kwargs = {inplace: True})\n",
            "    %input_21 : [num_users=1] = call_function[target=torch.nn.functional.dropout](args = (%input_20, 0.5, False, False), kwargs = {})\n",
            "    %input_22 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_21, %clone_default_15, %clone_default_16), kwargs = {})\n",
            "    return (input_22,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %l_self_modules_features_modules_0_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_0_parameters_weight_]\n",
            "    %l_self_modules_features_modules_0_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_0_parameters_bias_]\n",
            "    %l_x_ : torch.Tensor [num_users=1] = placeholder[target=L_x_]\n",
            "    %l_self_modules_features_modules_3_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_3_parameters_weight_]\n",
            "    %l_self_modules_features_modules_3_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_3_parameters_bias_]\n",
            "    %l_self_modules_features_modules_6_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_6_parameters_weight_]\n",
            "    %l_self_modules_features_modules_6_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_6_parameters_bias_]\n",
            "    %l_self_modules_features_modules_8_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_8_parameters_weight_]\n",
            "    %l_self_modules_features_modules_8_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_8_parameters_bias_]\n",
            "    %l_self_modules_features_modules_10_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_10_parameters_weight_]\n",
            "    %l_self_modules_features_modules_10_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_10_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_1_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_1_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_1_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_1_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_4_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_4_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_4_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_4_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_7_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_7_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_7_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_7_parameters_bias_]\n",
            "    %clone_default_16 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_7_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_15 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_7_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_14 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_4_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_13 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_4_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_12 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_1_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_11 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_1_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_10 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_10_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_9 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_10_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_8 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_8_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_7 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_8_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_6 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_6_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_5 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_6_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_4 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_3_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_3 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_3_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_2 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_x_,), kwargs = {})\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_0_parameters_bias_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_0_parameters_weight_,), kwargs = {})\n",
            "    %input_1 : [num_users=1] = call_function[target=torch.conv2d](args = (%clone_default_2, %clone_default, %clone_default_1, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_2 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_1,), kwargs = {inplace: True})\n",
            "    %input_3 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_2, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_4 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_3, %clone_default_3, %clone_default_4, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_5 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_4,), kwargs = {inplace: True})\n",
            "    %input_6 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_5, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_7 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_6, %clone_default_5, %clone_default_6, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_8 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_7,), kwargs = {inplace: True})\n",
            "    %input_9 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_8, %clone_default_7, %clone_default_8, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_10 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_9,), kwargs = {inplace: True})\n",
            "    %input_11 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_10, %clone_default_9, %clone_default_10, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_12 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_11,), kwargs = {inplace: True})\n",
            "    %input_13 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_12, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_14 : [num_users=1] = call_function[target=torch.nn.functional.adaptive_avg_pool2d](args = (%input_13, (6, 6)), kwargs = {})\n",
            "    %input_15 : [num_users=1] = call_method[target=flatten](args = (%input_14, 1, -1), kwargs = {})\n",
            "    %input_16 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_15, %clone_default_11, %clone_default_12), kwargs = {})\n",
            "    %input_17 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_16,), kwargs = {inplace: True})\n",
            "    %input_18 : [num_users=1] = call_function[target=torch.nn.functional.dropout](args = (%input_17, 0.5, False, False), kwargs = {})\n",
            "    %input_19 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_18, %clone_default_13, %clone_default_14), kwargs = {})\n",
            "    %input_20 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_19,), kwargs = {inplace: True})\n",
            "    %input_21 : [num_users=1] = call_function[target=torch.nn.functional.dropout](args = (%input_20, 0.5, False, False), kwargs = {})\n",
            "    %input_22 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_21, %clone_default_15, %clone_default_16), kwargs = {})\n",
            "    return (input_22,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %l_self_modules_features_modules_0_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_0_parameters_weight_]\n",
            "    %l_self_modules_features_modules_0_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_0_parameters_bias_]\n",
            "    %l_x_ : torch.Tensor [num_users=1] = placeholder[target=L_x_]\n",
            "    %l_self_modules_features_modules_3_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_3_parameters_weight_]\n",
            "    %l_self_modules_features_modules_3_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_3_parameters_bias_]\n",
            "    %l_self_modules_features_modules_6_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_6_parameters_weight_]\n",
            "    %l_self_modules_features_modules_6_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_6_parameters_bias_]\n",
            "    %l_self_modules_features_modules_8_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_8_parameters_weight_]\n",
            "    %l_self_modules_features_modules_8_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_8_parameters_bias_]\n",
            "    %l_self_modules_features_modules_10_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_10_parameters_weight_]\n",
            "    %l_self_modules_features_modules_10_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_features_modules_10_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_1_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_1_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_1_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_1_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_4_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_4_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_4_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_4_parameters_bias_]\n",
            "    %l_self_modules_classifier_modules_7_parameters_weight_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_7_parameters_weight_]\n",
            "    %l_self_modules_classifier_modules_7_parameters_bias_ : torch.nn.parameter.Parameter [num_users=1] = placeholder[target=L_self_modules_classifier_modules_7_parameters_bias_]\n",
            "    %clone_default_16 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_7_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_15 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_7_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_14 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_4_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_13 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_4_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_12 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_1_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_11 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_classifier_modules_1_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_10 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_10_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_9 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_10_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_8 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_8_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_7 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_8_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_6 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_6_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_5 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_6_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_4 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_3_parameters_bias_,), kwargs = {})\n",
            "    %clone_default_3 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_3_parameters_weight_,), kwargs = {})\n",
            "    %clone_default_2 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_x_,), kwargs = {})\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_0_parameters_bias_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_self_modules_features_modules_0_parameters_weight_,), kwargs = {})\n",
            "    %input_1 : [num_users=1] = call_function[target=torch.conv2d](args = (%clone_default_2, %clone_default, %clone_default_1, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_2 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_1,), kwargs = {inplace: True})\n",
            "    %input_3 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_2, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_4 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_3, %clone_default_3, %clone_default_4, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_5 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_4,), kwargs = {inplace: True})\n",
            "    %input_6 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_5, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_7 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_6, %clone_default_5, %clone_default_6, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_8 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_7,), kwargs = {inplace: True})\n",
            "    %input_9 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_8, %clone_default_7, %clone_default_8, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_10 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_9,), kwargs = {inplace: True})\n",
            "    %input_11 : [num_users=1] = call_function[target=torch.conv2d](args = (%input_10, %clone_default_9, %clone_default_10, (1, 1), (1, 1), (1, 1), 1), kwargs = {})\n",
            "    %input_12 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_11,), kwargs = {inplace: True})\n",
            "    %input_13 : [num_users=1] = call_function[target=torch.nn.functional.max_pool2d](args = (%input_12, 2, 2, 0, 1), kwargs = {ceil_mode: False, return_indices: False})\n",
            "    %input_14 : [num_users=1] = call_function[target=torch.nn.functional.adaptive_avg_pool2d](args = (%input_13, (6, 6)), kwargs = {})\n",
            "    %input_15 : [num_users=1] = call_method[target=flatten](args = (%input_14, 1, -1), kwargs = {})\n",
            "    %input_16 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_15, %clone_default_11, %clone_default_12), kwargs = {})\n",
            "    %input_17 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_16,), kwargs = {inplace: True})\n",
            "    %input_18 : [num_users=1] = call_function[target=torch.nn.functional.dropout](args = (%input_17, 0.5, False, False), kwargs = {})\n",
            "    %input_19 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_18, %clone_default_13, %clone_default_14), kwargs = {})\n",
            "    %input_20 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%input_19,), kwargs = {inplace: True})\n",
            "    %input_21 : [num_users=1] = call_function[target=torch.nn.functional.dropout](args = (%input_20, 0.5, False, False), kwargs = {})\n",
            "    %input_22 : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%input_21, %clone_default_15, %clone_default_16), kwargs = {})\n",
            "    return (input_22,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %arg5_1 : [num_users=1] = placeholder[target=arg5_1]\n",
            "    %arg6_1 : [num_users=1] = placeholder[target=arg6_1]\n",
            "    %arg7_1 : [num_users=1] = placeholder[target=arg7_1]\n",
            "    %arg8_1 : [num_users=1] = placeholder[target=arg8_1]\n",
            "    %arg9_1 : [num_users=1] = placeholder[target=arg9_1]\n",
            "    %arg10_1 : [num_users=1] = placeholder[target=arg10_1]\n",
            "    %arg11_1 : [num_users=1] = placeholder[target=arg11_1]\n",
            "    %arg12_1 : [num_users=1] = placeholder[target=arg12_1]\n",
            "    %arg13_1 : [num_users=1] = placeholder[target=arg13_1]\n",
            "    %arg14_1 : [num_users=1] = placeholder[target=arg14_1]\n",
            "    %arg15_1 : [num_users=1] = placeholder[target=arg15_1]\n",
            "    %arg16_1 : [num_users=1] = placeholder[target=arg16_1]\n",
            "    %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg16_1,), kwargs = {})\n",
            "    %clone_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg15_1,), kwargs = {})\n",
            "    %clone_2 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg14_1,), kwargs = {})\n",
            "    %clone_3 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg13_1,), kwargs = {})\n",
            "    %clone_4 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg12_1,), kwargs = {})\n",
            "    %clone_5 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg11_1,), kwargs = {})\n",
            "    %clone_6 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg10_1,), kwargs = {})\n",
            "    %clone_7 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg9_1,), kwargs = {})\n",
            "    %clone_8 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg8_1,), kwargs = {})\n",
            "    %clone_9 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg7_1,), kwargs = {})\n",
            "    %clone_10 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg6_1,), kwargs = {})\n",
            "    %clone_11 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg5_1,), kwargs = {})\n",
            "    %clone_12 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg4_1,), kwargs = {})\n",
            "    %clone_13 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg3_1,), kwargs = {})\n",
            "    %clone_14 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg2_1,), kwargs = {})\n",
            "    %clone_15 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg1_1,), kwargs = {})\n",
            "    %clone_16 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg0_1,), kwargs = {})\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%clone_14, %clone_16, %clone_15, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %max_pool2d_with_indices : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices, 0), kwargs = {})\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %clone_13, %clone_12, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})\n",
            "    %max_pool2d_with_indices_1 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu_1, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem_2 : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices_1, 0), kwargs = {})\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %clone_11, %clone_10, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %clone_9, %clone_8, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %clone_7, %clone_6, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})\n",
            "    %max_pool2d_with_indices_2 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu_4, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices_2, 0), kwargs = {})\n",
            "    %_adaptive_avg_pool2d : [num_users=1] = call_function[target=torch.ops.aten._adaptive_avg_pool2d.default](args = (%getitem_4, [6, 6]), kwargs = {})\n",
            "    %view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_adaptive_avg_pool2d, [1, 9216]), kwargs = {})\n",
            "    %permute : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%clone_5, [1, 0]), kwargs = {})\n",
            "    %addmm : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%clone_4, %view, %permute), kwargs = {})\n",
            "    %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm,), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_5,), kwargs = {})\n",
            "    %permute_1 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%clone_3, [1, 0]), kwargs = {})\n",
            "    %addmm_1 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%clone_2, %clone_17, %permute_1), kwargs = {})\n",
            "    %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm_1,), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_6,), kwargs = {})\n",
            "    %permute_2 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%clone_1, [1, 0]), kwargs = {})\n",
            "    %addmm_2 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%clone, %clone_18, %permute_2), kwargs = {})\n",
            "    return (addmm_2,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_16 from graph, since it is a clone node which is the only user of placeholder arg0_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_15 from graph, since it is a clone node which is the only user of placeholder arg1_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_14 from graph, since it is a clone node which is the only user of placeholder arg2_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_13 from graph, since it is a clone node which is the only user of placeholder arg3_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_12 from graph, since it is a clone node which is the only user of placeholder arg4_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_11 from graph, since it is a clone node which is the only user of placeholder arg5_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_10 from graph, since it is a clone node which is the only user of placeholder arg6_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_9 from graph, since it is a clone node which is the only user of placeholder arg7_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_8 from graph, since it is a clone node which is the only user of placeholder arg8_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_7 from graph, since it is a clone node which is the only user of placeholder arg9_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_6 from graph, since it is a clone node which is the only user of placeholder arg10_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_5 from graph, since it is a clone node which is the only user of placeholder arg11_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_4 from graph, since it is a clone node which is the only user of placeholder arg12_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_3 from graph, since it is a clone node which is the only user of placeholder arg13_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_2 from graph, since it is a clone node which is the only user of placeholder arg14_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_1 from graph, since it is a clone node which is the only user of placeholder arg15_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone from graph, since it is a clone node which is the only user of placeholder arg16_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removed auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %arg5_1 : [num_users=1] = placeholder[target=arg5_1]\n",
            "    %arg6_1 : [num_users=1] = placeholder[target=arg6_1]\n",
            "    %arg7_1 : [num_users=1] = placeholder[target=arg7_1]\n",
            "    %arg8_1 : [num_users=1] = placeholder[target=arg8_1]\n",
            "    %arg9_1 : [num_users=1] = placeholder[target=arg9_1]\n",
            "    %arg10_1 : [num_users=1] = placeholder[target=arg10_1]\n",
            "    %arg11_1 : [num_users=1] = placeholder[target=arg11_1]\n",
            "    %arg12_1 : [num_users=1] = placeholder[target=arg12_1]\n",
            "    %arg13_1 : [num_users=1] = placeholder[target=arg13_1]\n",
            "    %arg14_1 : [num_users=1] = placeholder[target=arg14_1]\n",
            "    %arg15_1 : [num_users=1] = placeholder[target=arg15_1]\n",
            "    %arg16_1 : [num_users=1] = placeholder[target=arg16_1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %arg0_1, %arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %max_pool2d_with_indices : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices, 0), kwargs = {})\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg3_1, %arg4_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})\n",
            "    %max_pool2d_with_indices_1 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu_1, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem_2 : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices_1, 0), kwargs = {})\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg5_1, %arg6_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg7_1, %arg8_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %arg9_1, %arg10_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})\n",
            "    %max_pool2d_with_indices_2 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu_4, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices_2, 0), kwargs = {})\n",
            "    %_adaptive_avg_pool2d : [num_users=1] = call_function[target=torch.ops.aten._adaptive_avg_pool2d.default](args = (%getitem_4, [6, 6]), kwargs = {})\n",
            "    %view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_adaptive_avg_pool2d, [1, 9216]), kwargs = {})\n",
            "    %permute : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%arg11_1, [1, 0]), kwargs = {})\n",
            "    %addmm : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%arg12_1, %view, %permute), kwargs = {})\n",
            "    %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm,), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_5,), kwargs = {})\n",
            "    %permute_1 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%arg13_1, [1, 0]), kwargs = {})\n",
            "    %addmm_1 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%arg14_1, %clone_17, %permute_1), kwargs = {})\n",
            "    %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm_1,), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_6,), kwargs = {})\n",
            "    %permute_2 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%arg15_1, [1, 0]), kwargs = {})\n",
            "    %addmm_2 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%arg16_1, %clone_18, %permute_2), kwargs = {})\n",
            "    return (addmm_2,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %arg5_1 : [num_users=1] = placeholder[target=arg5_1]\n",
            "    %arg6_1 : [num_users=1] = placeholder[target=arg6_1]\n",
            "    %arg7_1 : [num_users=1] = placeholder[target=arg7_1]\n",
            "    %arg8_1 : [num_users=1] = placeholder[target=arg8_1]\n",
            "    %arg9_1 : [num_users=1] = placeholder[target=arg9_1]\n",
            "    %arg10_1 : [num_users=1] = placeholder[target=arg10_1]\n",
            "    %arg11_1 : [num_users=1] = placeholder[target=arg11_1]\n",
            "    %arg12_1 : [num_users=1] = placeholder[target=arg12_1]\n",
            "    %arg13_1 : [num_users=1] = placeholder[target=arg13_1]\n",
            "    %arg14_1 : [num_users=1] = placeholder[target=arg14_1]\n",
            "    %arg15_1 : [num_users=1] = placeholder[target=arg15_1]\n",
            "    %arg16_1 : [num_users=1] = placeholder[target=arg16_1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %arg0_1, %arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %max_pool2d_with_indices : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices, 0), kwargs = {})\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg3_1, %arg4_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})\n",
            "    %max_pool2d_with_indices_1 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu_1, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem_2 : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices_1, 0), kwargs = {})\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg5_1, %arg6_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg7_1, %arg8_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %arg9_1, %arg10_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})\n",
            "    %max_pool2d_with_indices_2 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu_4, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices_2, 0), kwargs = {})\n",
            "    %_adaptive_avg_pool2d : [num_users=1] = call_function[target=torch.ops.aten._adaptive_avg_pool2d.default](args = (%getitem_4, [6, 6]), kwargs = {})\n",
            "    %view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_adaptive_avg_pool2d, [1, 9216]), kwargs = {})\n",
            "    %permute : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%arg11_1, [1, 0]), kwargs = {})\n",
            "    %addmm : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%arg12_1, %view, %permute), kwargs = {})\n",
            "    %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm,), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_5,), kwargs = {})\n",
            "    %permute_1 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%arg13_1, [1, 0]), kwargs = {})\n",
            "    %addmm_1 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%arg14_1, %clone_17, %permute_1), kwargs = {})\n",
            "    %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm_1,), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_6,), kwargs = {})\n",
            "    %permute_2 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%arg15_1, [1, 0]), kwargs = {})\n",
            "    %addmm_2 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%arg16_1, %clone_18, %permute_2), kwargs = {})\n",
            "    return (addmm_2,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.lower_linear:Graph after lowering linear:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %arg5_1 : [num_users=1] = placeholder[target=arg5_1]\n",
            "    %arg6_1 : [num_users=1] = placeholder[target=arg6_1]\n",
            "    %arg7_1 : [num_users=1] = placeholder[target=arg7_1]\n",
            "    %arg8_1 : [num_users=1] = placeholder[target=arg8_1]\n",
            "    %arg9_1 : [num_users=1] = placeholder[target=arg9_1]\n",
            "    %arg10_1 : [num_users=1] = placeholder[target=arg10_1]\n",
            "    %arg11_1 : [num_users=1] = placeholder[target=arg11_1]\n",
            "    %arg12_1 : [num_users=1] = placeholder[target=arg12_1]\n",
            "    %arg13_1 : [num_users=1] = placeholder[target=arg13_1]\n",
            "    %arg14_1 : [num_users=1] = placeholder[target=arg14_1]\n",
            "    %arg15_1 : [num_users=1] = placeholder[target=arg15_1]\n",
            "    %arg16_1 : [num_users=1] = placeholder[target=arg16_1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %arg0_1, %arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %max_pool2d_with_indices : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices, 0), kwargs = {})\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg3_1, %arg4_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})\n",
            "    %max_pool2d_with_indices_1 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu_1, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem_2 : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices_1, 0), kwargs = {})\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg5_1, %arg6_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg7_1, %arg8_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %arg9_1, %arg10_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})\n",
            "    %max_pool2d_with_indices_2 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d_with_indices.default](args = (%relu_4, [2, 2], [2, 2]), kwargs = {})\n",
            "    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%max_pool2d_with_indices_2, 0), kwargs = {})\n",
            "    %_adaptive_avg_pool2d : [num_users=1] = call_function[target=torch.ops.aten._adaptive_avg_pool2d.default](args = (%getitem_4, [6, 6]), kwargs = {})\n",
            "    %view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_adaptive_avg_pool2d, [1, 9216]), kwargs = {})\n",
            "    %linear_default : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%view, %arg11_1, %arg12_1), kwargs = {})\n",
            "    %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default,), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_5,), kwargs = {})\n",
            "    %linear_default_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_17, %arg13_1, %arg14_1), kwargs = {})\n",
            "    %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default_1,), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_6,), kwargs = {})\n",
            "    %linear_default_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_18, %arg15_1, %arg16_1), kwargs = {})\n",
            "    return (linear_default_2,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.replace_max_pool_with_indices:Replacing all uses of nodes max_pool2d_with_indices, getitem with fused maxpool node max_pool2d_default is the only user of placeholder max_pool2d_with_indices and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.replace_max_pool_with_indices:Replacing all uses of nodes max_pool2d_with_indices_1, getitem_2 with fused maxpool node max_pool2d_default_1 is the only user of placeholder max_pool2d_with_indices_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.replace_max_pool_with_indices:Replacing all uses of nodes max_pool2d_with_indices_2, getitem_4 with fused maxpool node max_pool2d_default_2 is the only user of placeholder max_pool2d_with_indices_2 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.replace_max_pool_with_indices:Graph after fusing maxpool operators with indices:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %arg5_1 : [num_users=1] = placeholder[target=arg5_1]\n",
            "    %arg6_1 : [num_users=1] = placeholder[target=arg6_1]\n",
            "    %arg7_1 : [num_users=1] = placeholder[target=arg7_1]\n",
            "    %arg8_1 : [num_users=1] = placeholder[target=arg8_1]\n",
            "    %arg9_1 : [num_users=1] = placeholder[target=arg9_1]\n",
            "    %arg10_1 : [num_users=1] = placeholder[target=arg10_1]\n",
            "    %arg11_1 : [num_users=1] = placeholder[target=arg11_1]\n",
            "    %arg12_1 : [num_users=1] = placeholder[target=arg12_1]\n",
            "    %arg13_1 : [num_users=1] = placeholder[target=arg13_1]\n",
            "    %arg14_1 : [num_users=1] = placeholder[target=arg14_1]\n",
            "    %arg15_1 : [num_users=1] = placeholder[target=arg15_1]\n",
            "    %arg16_1 : [num_users=1] = placeholder[target=arg16_1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %arg0_1, %arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %max_pool2d_default : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu, [2, 2], [2, 2]), kwargs = {})\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%max_pool2d_default, %arg3_1, %arg4_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})\n",
            "    %max_pool2d_default_1 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu_1, [2, 2], [2, 2]), kwargs = {})\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%max_pool2d_default_1, %arg5_1, %arg6_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg7_1, %arg8_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %arg9_1, %arg10_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})\n",
            "    %max_pool2d_default_2 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu_4, [2, 2], [2, 2]), kwargs = {})\n",
            "    %_adaptive_avg_pool2d : [num_users=1] = call_function[target=torch.ops.aten._adaptive_avg_pool2d.default](args = (%max_pool2d_default_2, [6, 6]), kwargs = {})\n",
            "    %view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_adaptive_avg_pool2d, [1, 9216]), kwargs = {})\n",
            "    %linear_default : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%view, %arg11_1, %arg12_1), kwargs = {})\n",
            "    %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default,), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_5,), kwargs = {})\n",
            "    %linear_default_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_17, %arg13_1, %arg14_1), kwargs = {})\n",
            "    %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default_1,), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_6,), kwargs = {})\n",
            "    %linear_default_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_18, %arg15_1, %arg16_1), kwargs = {})\n",
            "    return (linear_default_2,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.view_to_reshape:Graph after replacing view with reshape:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %arg5_1 : [num_users=1] = placeholder[target=arg5_1]\n",
            "    %arg6_1 : [num_users=1] = placeholder[target=arg6_1]\n",
            "    %arg7_1 : [num_users=1] = placeholder[target=arg7_1]\n",
            "    %arg8_1 : [num_users=1] = placeholder[target=arg8_1]\n",
            "    %arg9_1 : [num_users=1] = placeholder[target=arg9_1]\n",
            "    %arg10_1 : [num_users=1] = placeholder[target=arg10_1]\n",
            "    %arg11_1 : [num_users=1] = placeholder[target=arg11_1]\n",
            "    %arg12_1 : [num_users=1] = placeholder[target=arg12_1]\n",
            "    %arg13_1 : [num_users=1] = placeholder[target=arg13_1]\n",
            "    %arg14_1 : [num_users=1] = placeholder[target=arg14_1]\n",
            "    %arg15_1 : [num_users=1] = placeholder[target=arg15_1]\n",
            "    %arg16_1 : [num_users=1] = placeholder[target=arg16_1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %arg0_1, %arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %max_pool2d_default : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu, [2, 2], [2, 2]), kwargs = {})\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%max_pool2d_default, %arg3_1, %arg4_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})\n",
            "    %max_pool2d_default_1 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu_1, [2, 2], [2, 2]), kwargs = {})\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%max_pool2d_default_1, %arg5_1, %arg6_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg7_1, %arg8_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %arg9_1, %arg10_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})\n",
            "    %max_pool2d_default_2 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu_4, [2, 2], [2, 2]), kwargs = {})\n",
            "    %_adaptive_avg_pool2d : [num_users=1] = call_function[target=torch.ops.aten._adaptive_avg_pool2d.default](args = (%max_pool2d_default_2, [6, 6]), kwargs = {})\n",
            "    %reshape_default : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_adaptive_avg_pool2d, [1, 9216]), kwargs = {})\n",
            "    %linear_default : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%reshape_default, %arg11_1, %arg12_1), kwargs = {})\n",
            "    %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default,), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_5,), kwargs = {})\n",
            "    %linear_default_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_17, %arg13_1, %arg14_1), kwargs = {})\n",
            "    %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default_1,), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_6,), kwargs = {})\n",
            "    %linear_default_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_18, %arg15_1, %arg16_1), kwargs = {})\n",
            "    return (linear_default_2,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_assert_scalar:Removed 0 assert_scalar nodes:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %arg5_1 : [num_users=1] = placeholder[target=arg5_1]\n",
            "    %arg6_1 : [num_users=1] = placeholder[target=arg6_1]\n",
            "    %arg7_1 : [num_users=1] = placeholder[target=arg7_1]\n",
            "    %arg8_1 : [num_users=1] = placeholder[target=arg8_1]\n",
            "    %arg9_1 : [num_users=1] = placeholder[target=arg9_1]\n",
            "    %arg10_1 : [num_users=1] = placeholder[target=arg10_1]\n",
            "    %arg11_1 : [num_users=1] = placeholder[target=arg11_1]\n",
            "    %arg12_1 : [num_users=1] = placeholder[target=arg12_1]\n",
            "    %arg13_1 : [num_users=1] = placeholder[target=arg13_1]\n",
            "    %arg14_1 : [num_users=1] = placeholder[target=arg14_1]\n",
            "    %arg15_1 : [num_users=1] = placeholder[target=arg15_1]\n",
            "    %arg16_1 : [num_users=1] = placeholder[target=arg16_1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %arg0_1, %arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %max_pool2d_default : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu, [2, 2], [2, 2]), kwargs = {})\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%max_pool2d_default, %arg3_1, %arg4_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})\n",
            "    %max_pool2d_default_1 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu_1, [2, 2], [2, 2]), kwargs = {})\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%max_pool2d_default_1, %arg5_1, %arg6_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg7_1, %arg8_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %arg9_1, %arg10_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})\n",
            "    %max_pool2d_default_2 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu_4, [2, 2], [2, 2]), kwargs = {})\n",
            "    %_adaptive_avg_pool2d : [num_users=1] = call_function[target=torch.ops.aten._adaptive_avg_pool2d.default](args = (%max_pool2d_default_2, [6, 6]), kwargs = {})\n",
            "    %reshape_default : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_adaptive_avg_pool2d, [1, 9216]), kwargs = {})\n",
            "    %linear_default : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%reshape_default, %arg11_1, %arg12_1), kwargs = {})\n",
            "    %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default,), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_5,), kwargs = {})\n",
            "    %linear_default_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_17, %arg13_1, %arg14_1), kwargs = {})\n",
            "    %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default_1,), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_6,), kwargs = {})\n",
            "    %linear_default_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_18, %arg15_1, %arg16_1), kwargs = {})\n",
            "    return (linear_default_2,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %arg5_1 : [num_users=1] = placeholder[target=arg5_1]\n",
            "    %arg6_1 : [num_users=1] = placeholder[target=arg6_1]\n",
            "    %arg7_1 : [num_users=1] = placeholder[target=arg7_1]\n",
            "    %arg8_1 : [num_users=1] = placeholder[target=arg8_1]\n",
            "    %arg9_1 : [num_users=1] = placeholder[target=arg9_1]\n",
            "    %arg10_1 : [num_users=1] = placeholder[target=arg10_1]\n",
            "    %arg11_1 : [num_users=1] = placeholder[target=arg11_1]\n",
            "    %arg12_1 : [num_users=1] = placeholder[target=arg12_1]\n",
            "    %arg13_1 : [num_users=1] = placeholder[target=arg13_1]\n",
            "    %arg14_1 : [num_users=1] = placeholder[target=arg14_1]\n",
            "    %arg15_1 : [num_users=1] = placeholder[target=arg15_1]\n",
            "    %arg16_1 : [num_users=1] = placeholder[target=arg16_1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %arg0_1, %arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %max_pool2d_default : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu, [2, 2], [2, 2]), kwargs = {})\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%max_pool2d_default, %arg3_1, %arg4_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})\n",
            "    %max_pool2d_default_1 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu_1, [2, 2], [2, 2]), kwargs = {})\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%max_pool2d_default_1, %arg5_1, %arg6_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg7_1, %arg8_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %arg9_1, %arg10_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})\n",
            "    %max_pool2d_default_2 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu_4, [2, 2], [2, 2]), kwargs = {})\n",
            "    %_adaptive_avg_pool2d : [num_users=1] = call_function[target=torch.ops.aten._adaptive_avg_pool2d.default](args = (%max_pool2d_default_2, [6, 6]), kwargs = {})\n",
            "    %reshape_default : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_adaptive_avg_pool2d, [1, 9216]), kwargs = {})\n",
            "    %linear_default : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%reshape_default, %arg11_1, %arg12_1), kwargs = {})\n",
            "    %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default,), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_5,), kwargs = {})\n",
            "    %linear_default_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_17, %arg13_1, %arg14_1), kwargs = {})\n",
            "    %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default_1,), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_6,), kwargs = {})\n",
            "    %linear_default_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_18, %arg15_1, %arg16_1), kwargs = {})\n",
            "    return (linear_default_2,)\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.convolution.default + Operator Count: 5\n",
            "- torch.ops.aten.relu.default + Operator Count: 7\n",
            "- torch.ops.aten.max_pool2d.default + Operator Count: 3\n",
            "- torch.ops.aten._adaptive_avg_pool2d.default + Operator Count: 1\n",
            "- torch.ops.aten.reshape.default + Operator Count: 1\n",
            "- torch.ops.aten.linear.default + Operator Count: 3\n",
            "- torch.ops.aten.clone.default + Operator Count: 2\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Detected support for 22 operators out of 22 in subgraph.\n",
            "WARNING:torch_tensorrt.dynamo._compiler:Node linear_default of op type call_function does not have metadata. This could sometimes lead to undefined behavior.\n",
            "WARNING:torch_tensorrt.dynamo._compiler:Some nodes do not have metadata (shape and dtype information). This could lead to problems sometimes if the graph has PyTorch and TensorRT segments.\n",
            "INFO:torch_tensorrt.dynamo._compiler:Partitioning the graph via the fast partitioner\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Number of TensorRT-Accelerated Engines Generated: 1\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.convolution.default + Operator Count: 5\n",
            "- torch.ops.aten.relu.default + Operator Count: 7\n",
            "- torch.ops.aten.max_pool2d.default + Operator Count: 3\n",
            "- torch.ops.aten._adaptive_avg_pool2d.default + Operator Count: 1\n",
            "- torch.ops.aten.reshape.default + Operator Count: 1\n",
            "- torch.ops.aten.linear.default + Operator Count: 3\n",
            "- torch.ops.aten.clone.default + Operator Count: 2\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Converting submodule: _run_on_acc_0\n",
            " Input shapes: [(1, 3, 32, 32), (64, 3, 3, 3), (64,), (192, 64, 3, 3), (192,), (384, 192, 3, 3), (384,), (256, 384, 3, 3), (256,), (256, 256, 3, 3), (256,), (4096, 9216), (4096,), (4096, 4096), (4096,), (10, 4096), (10,)]\n",
            " graph():\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %arg0_1, %arg1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %max_pool2d_default : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu, [2, 2], [2, 2]), kwargs = {})\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%max_pool2d_default, %arg3_1, %arg4_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})\n",
            "    %max_pool2d_default_1 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu_1, [2, 2], [2, 2]), kwargs = {})\n",
            "    %arg5_1 : [num_users=1] = placeholder[target=arg5_1]\n",
            "    %arg6_1 : [num_users=1] = placeholder[target=arg6_1]\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%max_pool2d_default_1, %arg5_1, %arg6_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})\n",
            "    %arg7_1 : [num_users=1] = placeholder[target=arg7_1]\n",
            "    %arg8_1 : [num_users=1] = placeholder[target=arg8_1]\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg7_1, %arg8_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %arg9_1 : [num_users=1] = placeholder[target=arg9_1]\n",
            "    %arg10_1 : [num_users=1] = placeholder[target=arg10_1]\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %arg9_1, %arg10_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})\n",
            "    %max_pool2d_default_2 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%relu_4, [2, 2], [2, 2]), kwargs = {})\n",
            "    %_adaptive_avg_pool2d : [num_users=1] = call_function[target=torch.ops.aten._adaptive_avg_pool2d.default](args = (%max_pool2d_default_2, [6, 6]), kwargs = {})\n",
            "    %reshape_default : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_adaptive_avg_pool2d, [1, 9216]), kwargs = {})\n",
            "    %arg11_1 : [num_users=1] = placeholder[target=arg11_1]\n",
            "    %arg12_1 : [num_users=1] = placeholder[target=arg12_1]\n",
            "    %linear_default : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%reshape_default, %arg11_1, %arg12_1), kwargs = {})\n",
            "    %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default,), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_5,), kwargs = {})\n",
            "    %arg13_1 : [num_users=1] = placeholder[target=arg13_1]\n",
            "    %arg14_1 : [num_users=1] = placeholder[target=arg14_1]\n",
            "    %linear_default_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_17, %arg13_1, %arg14_1), kwargs = {})\n",
            "    %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_default_1,), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%relu_6,), kwargs = {})\n",
            "    %arg15_1 : [num_users=1] = placeholder[target=arg15_1]\n",
            "    %arg16_1 : [num_users=1] = placeholder[target=arg16_1]\n",
            "    %linear_default_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_18, %arg15_1, %arg16_1), kwargs = {})\n",
            "    return linear_default_2\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node arg2_1 (kind: arg2_1, args: ())\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg2_1 [shape=[1, 3, 32, 32], dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node arg2_1 [arg2_1] (Inputs: () | Outputs: (arg2_1: (1, 3, 32, 32)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node arg0_1 (kind: arg0_1, args: ())\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg0_1 [shape=[64, 3, 3, 3], dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node arg0_1 [arg0_1] (Inputs: () | Outputs: (arg0_1: (64, 3, 3, 3)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node arg1_1 (kind: arg1_1, args: ())\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg1_1 [shape=[64], dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node arg1_1 [arg1_1] (Inputs: () | Outputs: (arg1_1: (64,)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution (kind: aten.convolution.default, args: ('arg2_1 <Node>', 'arg0_1 <Node>', 'arg1_1 <Node>', ['1 <int>', '1 <int>'], ['1 <int>', '1 <int>'], ['1 <int>', '1 <int>'], 'False <bool>', ['0 <int>', '0 <int>'], '1 <int>'))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node convolution [aten.convolution.default] (Inputs: (arg2_1: (1, 3, 32, 32)@torch.float32, arg0_1: (64, 3, 3, 3)@torch.float32, arg1_1: (64,)@torch.float32, [1, 1], [1, 1], [1, 1], False, [0, 0], 1) | Outputs: (convolution: (1, 64, 32, 32)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu (kind: aten.relu.default, args: ('convolution <Node>',))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node relu [aten.relu.default] (Inputs: (convolution: (1, 64, 32, 32)@torch.float32) | Outputs: (relu: (1, 64, 32, 32)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node max_pool2d_default (kind: aten.max_pool2d.default, args: ('relu <Node>', ['2 <int>', '2 <int>'], ['2 <int>', '2 <int>']))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node max_pool2d_default [aten.max_pool2d.default] (Inputs: (relu: (1, 64, 32, 32)@torch.float32, [2, 2], [2, 2]) | Outputs: (max_pool2d_default: (1, 64, 16, 16)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node arg3_1 (kind: arg3_1, args: ())\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg3_1 [shape=[192, 64, 3, 3], dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node arg3_1 [arg3_1] (Inputs: () | Outputs: (arg3_1: (192, 64, 3, 3)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node arg4_1 (kind: arg4_1, args: ())\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg4_1 [shape=[192], dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node arg4_1 [arg4_1] (Inputs: () | Outputs: (arg4_1: (192,)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_1 (kind: aten.convolution.default, args: ('max_pool2d_default <Node>', 'arg3_1 <Node>', 'arg4_1 <Node>', ['1 <int>', '1 <int>'], ['1 <int>', '1 <int>'], ['1 <int>', '1 <int>'], 'False <bool>', ['0 <int>', '0 <int>'], '1 <int>'))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node convolution_1 [aten.convolution.default] (Inputs: (max_pool2d_default: (1, 64, 16, 16)@torch.float32, arg3_1: (192, 64, 3, 3)@torch.float32, arg4_1: (192,)@torch.float32, [1, 1], [1, 1], [1, 1], False, [0, 0], 1) | Outputs: (convolution_1: (1, 192, 16, 16)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_1 (kind: aten.relu.default, args: ('convolution_1 <Node>',))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node relu_1 [aten.relu.default] (Inputs: (convolution_1: (1, 192, 16, 16)@torch.float32) | Outputs: (relu_1: (1, 192, 16, 16)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node max_pool2d_default_1 (kind: aten.max_pool2d.default, args: ('relu_1 <Node>', ['2 <int>', '2 <int>'], ['2 <int>', '2 <int>']))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node max_pool2d_default_1 [aten.max_pool2d.default] (Inputs: (relu_1: (1, 192, 16, 16)@torch.float32, [2, 2], [2, 2]) | Outputs: (max_pool2d_default_1: (1, 192, 8, 8)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node arg5_1 (kind: arg5_1, args: ())\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg5_1 [shape=[384, 192, 3, 3], dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node arg5_1 [arg5_1] (Inputs: () | Outputs: (arg5_1: (384, 192, 3, 3)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node arg6_1 (kind: arg6_1, args: ())\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg6_1 [shape=[384], dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node arg6_1 [arg6_1] (Inputs: () | Outputs: (arg6_1: (384,)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_2 (kind: aten.convolution.default, args: ('max_pool2d_default_1 <Node>', 'arg5_1 <Node>', 'arg6_1 <Node>', ['1 <int>', '1 <int>'], ['1 <int>', '1 <int>'], ['1 <int>', '1 <int>'], 'False <bool>', ['0 <int>', '0 <int>'], '1 <int>'))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node convolution_2 [aten.convolution.default] (Inputs: (max_pool2d_default_1: (1, 192, 8, 8)@torch.float32, arg5_1: (384, 192, 3, 3)@torch.float32, arg6_1: (384,)@torch.float32, [1, 1], [1, 1], [1, 1], False, [0, 0], 1) | Outputs: (convolution_2: (1, 384, 8, 8)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_2 (kind: aten.relu.default, args: ('convolution_2 <Node>',))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node relu_2 [aten.relu.default] (Inputs: (convolution_2: (1, 384, 8, 8)@torch.float32) | Outputs: (relu_2: (1, 384, 8, 8)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node arg7_1 (kind: arg7_1, args: ())\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg7_1 [shape=[256, 384, 3, 3], dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node arg7_1 [arg7_1] (Inputs: () | Outputs: (arg7_1: (256, 384, 3, 3)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node arg8_1 (kind: arg8_1, args: ())\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg8_1 [shape=[256], dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node arg8_1 [arg8_1] (Inputs: () | Outputs: (arg8_1: (256,)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_3 (kind: aten.convolution.default, args: ('relu_2 <Node>', 'arg7_1 <Node>', 'arg8_1 <Node>', ['1 <int>', '1 <int>'], ['1 <int>', '1 <int>'], ['1 <int>', '1 <int>'], 'False <bool>', ['0 <int>', '0 <int>'], '1 <int>'))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node convolution_3 [aten.convolution.default] (Inputs: (relu_2: (1, 384, 8, 8)@torch.float32, arg7_1: (256, 384, 3, 3)@torch.float32, arg8_1: (256,)@torch.float32, [1, 1], [1, 1], [1, 1], False, [0, 0], 1) | Outputs: (convolution_3: (1, 256, 8, 8)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_3 (kind: aten.relu.default, args: ('convolution_3 <Node>',))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node relu_3 [aten.relu.default] (Inputs: (convolution_3: (1, 256, 8, 8)@torch.float32) | Outputs: (relu_3: (1, 256, 8, 8)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node arg9_1 (kind: arg9_1, args: ())\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg9_1 [shape=[256, 256, 3, 3], dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node arg9_1 [arg9_1] (Inputs: () | Outputs: (arg9_1: (256, 256, 3, 3)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node arg10_1 (kind: arg10_1, args: ())\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg10_1 [shape=[256], dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node arg10_1 [arg10_1] (Inputs: () | Outputs: (arg10_1: (256,)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_4 (kind: aten.convolution.default, args: ('relu_3 <Node>', 'arg9_1 <Node>', 'arg10_1 <Node>', ['1 <int>', '1 <int>'], ['1 <int>', '1 <int>'], ['1 <int>', '1 <int>'], 'False <bool>', ['0 <int>', '0 <int>'], '1 <int>'))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node convolution_4 [aten.convolution.default] (Inputs: (relu_3: (1, 256, 8, 8)@torch.float32, arg9_1: (256, 256, 3, 3)@torch.float32, arg10_1: (256,)@torch.float32, [1, 1], [1, 1], [1, 1], False, [0, 0], 1) | Outputs: (convolution_4: (1, 256, 8, 8)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_4 (kind: aten.relu.default, args: ('convolution_4 <Node>',))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node relu_4 [aten.relu.default] (Inputs: (convolution_4: (1, 256, 8, 8)@torch.float32) | Outputs: (relu_4: (1, 256, 8, 8)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node max_pool2d_default_2 (kind: aten.max_pool2d.default, args: ('relu_4 <Node>', ['2 <int>', '2 <int>'], ['2 <int>', '2 <int>']))\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node max_pool2d_default_2 [aten.max_pool2d.default] (Inputs: (relu_4: (1, 256, 8, 8)@torch.float32, [2, 2], [2, 2]) | Outputs: (max_pool2d_default_2: (1, 256, 4, 4)@torch.float32))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _adaptive_avg_pool2d (kind: aten._adaptive_avg_pool2d.default, args: ('max_pool2d_default_2 <Node>', ['6 <int>', '6 <int>']))\n",
            "ERROR:torch_tensorrt [TensorRT Conversion Context]:ILayer::setName: Error Code 3: API Usage Error (Failed attempt to rename a layer from (Unnamed Layer* 49) [Constant] to _adaptive_avg_pool2d_select_-1_indices_tensor as the new name is already in use.)\n",
            "ERROR:torch_tensorrt [TensorRT Conversion Context]:ILayer::setName: Error Code 3: API Usage Error (Failed attempt to rename a layer from (Unnamed Layer* 51) [Shuffle] to [SHUFFLE]-[aten_ops._adaptive_avg_pool2d.default]-[_adaptive_avg_pool2d_reshape_-1] as the new name is already in use.)\n",
            "ERROR:torch_tensorrt [TensorRT Conversion Context]:ILayer::setName: Error Code 3: API Usage Error (Failed attempt to rename a layer from (Unnamed Layer* 59) [Constant] to _adaptive_avg_pool2d_select_-2_indices_tensor as the new name is already in use.)\n",
            "ERROR:torch_tensorrt [TensorRT Conversion Context]:ILayer::setName: Error Code 3: API Usage Error (Failed attempt to rename a layer from (Unnamed Layer* 61) [Shuffle] to [SHUFFLE]-[aten_ops._adaptive_avg_pool2d.default]-[_adaptive_avg_pool2d_reshape_-2] as the new name is already in use.)\n",
            "ERROR:torch_tensorrt [TensorRT Conversion Context]:ITensor::getDimensions: Error Code 4: Internal Error ([CONCATENATION]-[aten_ops._adaptive_avg_pool2d.default]-[_adaptive_avg_pool2d_cat_-1_gather]: all concat input tensors must have the same dimensions except on the concatenation axis (3), but dimensions mismatched at index 2. Input 0 shape: [1,256,5,2], Input 1 shape: [1,256,4,1])\n",
            "ERROR:torch_tensorrt [TensorRT Conversion Context]:ITensor::getDimensions: Error Code 4: API Usage Error (Output shape can not be computed for node [CONCATENATION]-[aten_ops._adaptive_avg_pool2d.default]-[_adaptive_avg_pool2d_cat_-1_gather].)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during inference: backend='torch_tensorrt_backend' raised:\n",
            "ValueError: __len__() should return >= 0\n",
            "\n",
            "While executing %_adaptive_avg_pool2d : [num_users=1] = call_function[target=torch.ops.aten._adaptive_avg_pool2d.default](args = (%max_pool2d_default_2, [6, 6]), kwargs = {_itensor_to_tensor_meta: {<tensorrt_bindings.tensorrt.ITensor object at 0x7cc010b9a630>: ((1, 3, 32, 32), torch.float32, False, (3072, 1024, 32, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a85670>: ((64, 3, 3, 3), torch.float32, True, (27, 9, 3, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a96230>: ((64,), torch.float32, True, (1,), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010b6ae70>: ((1, 64, 32, 32), torch.float32, False, (65536, 1024, 32, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010b402f0>: ((1, 64, 32, 32), torch.float32, False, (65536, 1024, 32, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a858f0>: None, <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2c2f0>: ((192, 64, 3, 3), torch.float32, True, (576, 9, 3, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2ca70>: ((192,), torch.float32, True, (1,), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2cdb0>: ((1, 192, 16, 16), torch.float32, False, (49152, 256, 16, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2d170>: ((1, 192, 16, 16), torch.float32, False, (49152, 256, 16, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2caf0>: None, <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2d670>: ((384, 192, 3, 3), torch.float32, True, (1728, 9, 3, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2db70>: ((384,), torch.float32, True, (1,), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2e470>: ((1, 384, 8, 8), torch.float32, False, (24576, 64, 8, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2e130>: ((1, 384, 8, 8), torch.float32, False, (24576, 64, 8, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2e970>: ((256, 384, 3, 3), torch.float32, True, (3456, 9, 3, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2eb30>: ((256,), torch.float32, True, (1,), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2dfb0>: ((1, 256, 8, 8), torch.float32, False, (16384, 64, 8, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2f970>: ((1, 256, 8, 8), torch.float32, False, (16384, 64, 8, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a97f30>: ((256, 256, 3, 3), torch.float32, True, (2304, 9, 3, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a2fef0>: ((256,), torch.float32, True, (1,), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a38630>: ((1, 256, 8, 8), torch.float32, False, (16384, 64, 8, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a385b0>: ((1, 256, 8, 8), torch.float32, False, (16384, 64, 8, 1), torch.contiguous_format, False, {}), <tensorrt_bindings.tensorrt.ITensor object at 0x7cc010a38930>: None}})\n",
            "Original traceback:\n",
            "None\n",
            "\n",
            "Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
            "\n",
            "\n",
            "You can suppress this exception and fall back to eager by setting:\n",
            "    import torch._dynamo\n",
            "    torch._dynamo.config.suppress_errors = True\n",
            "\n",
            "Torch-TensorRT 최적화 모델 평균 Inference 시간: 0.026275 초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 결과 출력\n",
        "speedup = original_time / optimized_time\n",
        "print(f'Torch-TensorRT 적용으로 인한 Inference 속도 향상: {speedup:.2f}배')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0IoA0EDC8Fm",
        "outputId": "0dc593a7-7a83-45cd-ee06-43c94682f74e"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch-TensorRT 적용으로 인한 Inference 속도 향상: 0.07배\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch 유틸리티로 작업 공간 정리\n",
        "torch._dynamo.reset()"
      ],
      "metadata": {
        "id": "nMdxyYhvC8DV"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. PyTorch JIT Trace 모드 적용"
      ],
      "metadata": {
        "id": "GtU1xc3FDiKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 JIT Trace 모드로 변환\n",
        "traced_model = torch.jit.trace(model, torch.rand((1, 3, 32, 32)).to(device))"
      ],
      "metadata": {
        "id": "4oCQgSDsC3lU"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JIT Trace 모델 Inference 시간 측정\n",
        "jit_time = measure_inference_time(traced_model, inputs)\n",
        "print(f'JIT Trace 모델 평균 Inference 시간: {jit_time:.6f} 초')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LACQ9FyEC5Mh",
        "outputId": "6dd55279-0b16-443a-86b4-0d6cb1a06289",
        "collapsed": true
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JIT Trace 모델 평균 Inference 시간: 0.001088 초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 결과 출력\n",
        "jit_speedup = original_time / jit_time\n",
        "print(f'JIT Trace 적용으로 인한 Inference 속도 향상: {jit_speedup:.2f}배')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQpe77jaC69Z",
        "outputId": "f61ac7ba-55ba-482e-b00b-4a96f8fc7cf7"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JIT Trace 적용으로 인한 Inference 속도 향상: 1.68배\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JIT Trace 모델 그래프 및 코드 출력\n",
        "print(traced_model.graph)\n",
        "print(traced_model.code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lsp_lqEC8eE",
        "outputId": "4bf437a5-7052-410d-f59d-6ba3b228eebd",
        "collapsed": true
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph(%self.1 : __torch__.___torch_mangle_290.AlexNet,\n",
            "      %x : Float(1, 3, 32, 32, strides=[3072, 1024, 32, 1], requires_grad=0, device=cuda:0)):\n",
            "  %classifier : __torch__.torch.nn.modules.container.___torch_mangle_289.Sequential = prim::GetAttr[name=\"classifier\"](%self.1)\n",
            "  %features : __torch__.torch.nn.modules.container.___torch_mangle_280.Sequential = prim::GetAttr[name=\"features\"](%self.1)\n",
            "  %352 : Tensor = prim::CallMethod[name=\"forward\"](%features, %x)\n",
            "  %353 : Tensor = prim::CallMethod[name=\"forward\"](%classifier, %352)\n",
            "  return (%353)\n",
            "\n",
            "def forward(self,\n",
            "    x: Tensor) -> Tensor:\n",
            "  classifier = self.classifier\n",
            "  features = self.features\n",
            "  _0 = (classifier).forward((features).forward(x, ), )\n",
            "  return _0\n",
            "\n"
          ]
        }
      ]
    }
  ]
}