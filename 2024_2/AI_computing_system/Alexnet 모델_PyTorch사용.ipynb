{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "PA741zxumnWz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 데이터 로드 및 전처리"
      ],
      "metadata": {
        "id": "WjgmWGyhmoK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Eo3w3yOumqO2",
        "outputId": "01f51608-3695-4379-ebb6-28ebf3c48df0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 49273764.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Alexnet 모델 정의 (PyTorch 사용)"
      ],
      "metadata": {
        "id": "vPehjz8anXEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features  = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.AdaptiveAvgPool2d((6, 6))\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Q4WbEcMypTnf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 모델 학습 설정"
      ],
      "metadata": {
        "id": "Io3bOf81nqxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 모델 학습 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = AlexNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "hosUdWIXntUO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 모델 학습"
      ],
      "metadata": {
        "id": "1kDV6HNjoifz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "patience = 2  # Early stopping patience\n",
        "best_loss = float('inf')\n",
        "stopping_step = 0\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 기존의 기울기 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 + 역전파 + 최적화\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 값 출력\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:    # 매 100 미니배치마다 출력\n",
        "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "        # Early stopping 조건 확인\n",
        "    if running_loss < best_loss:\n",
        "        best_loss = running_loss\n",
        "        stopping_step = 0\n",
        "    else:\n",
        "        stopping_step += 1\n",
        "        if stopping_step >= patience:\n",
        "            print('Early stopping triggered')\n",
        "            break\n",
        "\n",
        "print('학습 완료')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFPPlxt9ZPgx",
        "outputId": "9fbd7b63-6c2e-4b29-bc96-bb561f3f6415"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 100] loss: 2.011\n",
            "[Epoch 1, Batch 200] loss: 1.641\n",
            "[Epoch 1, Batch 300] loss: 1.488\n",
            "[Epoch 2, Batch 100] loss: 1.252\n",
            "[Epoch 2, Batch 200] loss: 1.206\n",
            "[Epoch 2, Batch 300] loss: 1.133\n",
            "[Epoch 3, Batch 100] loss: 0.999\n",
            "[Epoch 3, Batch 200] loss: 0.962\n",
            "[Epoch 3, Batch 300] loss: 0.928\n",
            "[Epoch 4, Batch 100] loss: 0.808\n",
            "[Epoch 4, Batch 200] loss: 0.824\n",
            "[Epoch 4, Batch 300] loss: 0.803\n",
            "[Epoch 5, Batch 100] loss: 0.690\n",
            "[Epoch 5, Batch 200] loss: 0.690\n",
            "[Epoch 5, Batch 300] loss: 0.695\n",
            "[Epoch 6, Batch 100] loss: 0.592\n",
            "[Epoch 6, Batch 200] loss: 0.623\n",
            "[Epoch 6, Batch 300] loss: 0.620\n",
            "[Epoch 7, Batch 100] loss: 0.510\n",
            "[Epoch 7, Batch 200] loss: 0.550\n",
            "[Epoch 7, Batch 300] loss: 0.558\n",
            "[Epoch 8, Batch 100] loss: 0.453\n",
            "[Epoch 8, Batch 200] loss: 0.484\n",
            "[Epoch 8, Batch 300] loss: 0.506\n",
            "[Epoch 9, Batch 100] loss: 0.407\n",
            "[Epoch 9, Batch 200] loss: 0.428\n",
            "[Epoch 9, Batch 300] loss: 0.441\n",
            "[Epoch 10, Batch 100] loss: 0.346\n",
            "[Epoch 10, Batch 200] loss: 0.375\n",
            "[Epoch 10, Batch 300] loss: 0.406\n",
            "[Epoch 11, Batch 100] loss: 0.316\n",
            "[Epoch 11, Batch 200] loss: 0.337\n",
            "[Epoch 11, Batch 300] loss: 0.354\n",
            "[Epoch 12, Batch 100] loss: 0.284\n",
            "[Epoch 12, Batch 200] loss: 0.304\n",
            "[Epoch 12, Batch 300] loss: 0.331\n",
            "[Epoch 13, Batch 100] loss: 0.240\n",
            "[Epoch 13, Batch 200] loss: 0.273\n",
            "[Epoch 13, Batch 300] loss: 0.321\n",
            "[Epoch 14, Batch 100] loss: 0.216\n",
            "[Epoch 14, Batch 200] loss: 0.298\n",
            "[Epoch 14, Batch 300] loss: 0.265\n",
            "[Epoch 15, Batch 100] loss: 0.206\n",
            "[Epoch 15, Batch 200] loss: 0.252\n",
            "[Epoch 15, Batch 300] loss: 0.266\n",
            "[Epoch 16, Batch 100] loss: 0.198\n",
            "[Epoch 16, Batch 200] loss: 0.233\n",
            "[Epoch 16, Batch 300] loss: 0.253\n",
            "[Epoch 17, Batch 100] loss: 0.205\n",
            "[Epoch 17, Batch 200] loss: 0.202\n",
            "[Epoch 17, Batch 300] loss: 0.216\n",
            "[Epoch 18, Batch 100] loss: 0.169\n",
            "[Epoch 18, Batch 200] loss: 0.196\n",
            "[Epoch 18, Batch 300] loss: 0.230\n",
            "[Epoch 19, Batch 100] loss: 0.179\n",
            "[Epoch 19, Batch 200] loss: 0.205\n",
            "[Epoch 19, Batch 300] loss: 0.206\n",
            "[Epoch 20, Batch 100] loss: 0.170\n",
            "[Epoch 20, Batch 200] loss: 0.199\n",
            "[Epoch 20, Batch 300] loss: 0.203\n",
            "학습 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 모델 평가"
      ],
      "metadata": {
        "id": "MN2sBKQuttZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 테스트 정확도 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'최종 테스트 정확도: {100 * correct / total:.4f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjBZmFMnntN1",
        "outputId": "d6c1ff56-f83a-42bc-ba99-c5333252ff36"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 테스트 정확도: 76.5400%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dsris1aGntK1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Pp3zsydnU8k"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}