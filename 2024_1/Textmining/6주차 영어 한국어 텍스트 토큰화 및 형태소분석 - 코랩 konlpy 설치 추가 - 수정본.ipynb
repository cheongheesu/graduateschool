{"cells":[{"cell_type":"markdown","metadata":{"id":"__j4vwduCuyv"},"source":["## NLTK를 이용한 영어 텍스트 품사 태깅\n","NLTK는 먼저 토큰화를 하고 토큰들에 대한 품사 태깅을 수행함"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4PteF3yZCuyx","outputId":"26402104-dc00-4260-a389-353b0518c775"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('Hello', 'NNP'), ('everyone', 'NN'), ('.', '.'), ('It', 'PRP'), (\"'s\", 'VBZ'), ('good', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), ('.', '.'), ('Let', 'VB'), (\"'s\", 'POS'), ('start', 'VB'), ('our', 'PRP$'), ('text', 'NN'), ('mining', 'NN'), ('class', 'NN'), ('!', '.')]\n","[('It', 'PRP'), (\"'s\", 'VBZ'), ('an', 'DT'), ('unexpected', 'JJ'), ('thing', 'NN'), ('.', '.')]\n","[('unexpected', 'JJ')]\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","\n","tokens = word_tokenize(\"Hello everyone. It's good to see you. Let's start our text mining class!\")\n","\n","print(nltk.pos_tag(tokens))   # 품사 태깅 결과를 (단어, 품사)로 구성된 튜플의 리스트로 반환\n","\n","tokens = word_tokenize(\"It's an unexpected thing.\")\n","print(nltk.pos_tag(tokens))\n","print(nltk.pos_tag(['unexpected']))"]},{"cell_type":"markdown","metadata":{"id":"_MKfCjFCCuyy"},"source":["NLTK는 펜 트리뱅크 태그 세트를 사용하므로 해당 표를 보면 품사 약어의 의미를 알 수 있음  \n","아래와 같이 품사 약어의 의미와 설명을 볼 수도 있음"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sqC-TF3xCuyy","outputId":"c9e35416-7546-4587-f3a3-9470bc95b1fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["CC: conjunction, coordinating\n","    & 'n and both but either et for less minus neither nor or plus so\n","    therefore times v. versus vs. whether yet\n","RB: adverb\n","    occasionally unabatingly maddeningly adventurously professedly\n","    stirringly prominently technologically magisterially predominately\n","    swiftly fiscally pitilessly ...\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package tagsets to\n","[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n"]}],"source":["nltk.download('tagsets')  # 태그셋 다운로드\n","\n","nltk.help.upenn_tagset('CC')\n","nltk.help.upenn_tagset('RB')"]},{"cell_type":"markdown","metadata":{"id":"7xv3vDwICuyy"},"source":["특정 품사만을 추출하여 분석할 경우는 다음 예시 코드 활용"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqhDUIu1Cuyy","outputId":"eee3acd3-1c9e-4f66-c57b-bddb009f2eb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('Hello', 'NNP'), ('everyone', 'NN'), ('.', '.'), ('It', 'PRP'), (\"'s\", 'VBZ'), ('good', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), ('.', '.'), ('Let', 'VB'), (\"'s\", 'POS'), ('start', 'VB'), ('our', 'PRP$'), ('text', 'NN'), ('mining', 'NN'), ('class', 'NN'), ('!', '.')]\n","my_words:  ['everyone', 'good', 'see', 'Let', 'start', 'text', 'mining', 'class']\n"]}],"source":["my_tag_set = ['NN', 'VB', 'JJ']\n","\n","tokens = word_tokenize(\"Hello everyone. It's good to see you. Let's start our text mining class!\")\n","\n","print(nltk.pos_tag(tokens))\n","\n","my_words = [word for word, tag in nltk.pos_tag(tokens) if tag in my_tag_set]\n","\n","print('my_words: ', my_words)"]},{"cell_type":"markdown","metadata":{"id":"MgVNKW7hCuyz"},"source":["동음이의어를 처리하거나 품사를 이용해 단어를 더욱 정확하게 구분하고 싶을 때는 다음과 같이 단어 뒤에 품사 태그를 붙여 사용  \n","BOW(Bag Of Words)를 이용한 문서 분류에서 품사 정보 추가시 성능 차이가 있음"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIGDOXRaCuyz","outputId":"e837e412-2497-4b1f-a7b2-33c9fd3dc3e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Hello/NNP', 'everyone/NN', './.', 'It/PRP', \"'s/VBZ\", 'good/JJ', 'to/TO', 'see/VB', 'you/PRP', './.', 'Let/VB', \"'s/POS\", 'start/VB', 'our/PRP$', 'text/NN', 'mining/NN', 'class/NN', '!/.']\n"]}],"source":["words_with_tag = ['/'.join(item) for item in nltk.pos_tag(tokens)]   # 단어와 토큰을 붙여 서로 다른 품사의 같은 형태 단어를 다른 단어로\n","print(words_with_tag)"]},{"cell_type":"markdown","metadata":{"id":"wI0nLu-1Cuyz"},"source":["## KoNLPy를 이용한 한국어 텍스트 형태소 분석 및 품사 태깅\n","KoNLPy는 토큰화를 미리 하지 않고 형태소 분석 및 품사 태깅 함수가 토큰화를 함께 수행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lW-HRpJTCuyz"},"outputs":[],"source":["# konlpy를 코랩에서 설치하기\n","# !curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5OwK_wt_Cuyz","executionInfo":{"status":"ok","timestamp":1712674817973,"user_tz":-540,"elapsed":1461,"user":{"displayName":"Hyun-jung Park","userId":"04909012304343075962"}}},"outputs":[],"source":["from konlpy.tag import Okt\n","\n","Okt = Okt()"]},{"cell_type":"code","execution_count":4,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"n5BJNmZECuyz","executionInfo":{"status":"ok","timestamp":1712674832657,"user_tz":-540,"elapsed":5895,"user":{"displayName":"Hyun-jung Park","userId":"04909012304343075962"}},"outputId":"2a356a33-b5f6-4342-a824-a2b3d9e812fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["형태소: ['절망', '의', '반대', '가', '희망', '은', '아니다', '.', '\\n', '어', '두운', '밤하늘', '에', '별', '이', '빛나듯', '\\n', '희망', '은', '절망', '속', '에', '싹트는', '거지', '\\n', '만약', '에', '우리', '가', '희망', '함', '이', '적다면', '\\n', '그', '누가', '세상', '을', '비출어줄까', '.', '\\n', '정희성', ',', '희망', '공부']\n","\n","명사: ['절망', '반대', '희망', '어', '두운', '밤하늘', '별', '희망', '절망', '속', '거지', '만약', '우리', '희망', '함', '그', '누가', '세상', '정희성', '희망', '공부']\n","\n","품사 태깅 결과: [('절망', 'Noun'), ('의', 'Josa'), ('반대', 'Noun'), ('가', 'Josa'), ('희망', 'Noun'), ('은', 'Josa'), ('아니다', 'Adjective'), ('.', 'Punctuation'), ('\\n', 'Foreign'), ('어', 'Noun'), ('두운', 'Noun'), ('밤하늘', 'Noun'), ('에', 'Josa'), ('별', 'Noun'), ('이', 'Josa'), ('빛나듯', 'Verb'), ('\\n', 'Foreign'), ('희망', 'Noun'), ('은', 'Josa'), ('절망', 'Noun'), ('속', 'Noun'), ('에', 'Josa'), ('싹트는', 'Verb'), ('거지', 'Noun'), ('\\n', 'Foreign'), ('만약', 'Noun'), ('에', 'Josa'), ('우리', 'Noun'), ('가', 'Josa'), ('희망', 'Noun'), ('함', 'Noun'), ('이', 'Josa'), ('적다면', 'Verb'), ('\\n', 'Foreign'), ('그', 'Noun'), ('누가', 'Noun'), ('세상', 'Noun'), ('을', 'Josa'), ('비출어줄까', 'Verb'), ('.', 'Punctuation'), ('\\n', 'Foreign'), ('정희성', 'Noun'), (',', 'Punctuation'), ('희망', 'Noun'), ('공부', 'Noun')]\n","[('강아지', 'Noun'), ('가', 'Josa'), ('아파서', 'Adjective'), ('약', 'Noun'), ('을', 'Josa'), ('먹이', 'Noun'), ('다', 'Josa'), ('.', 'Punctuation')]\n"]},{"output_type":"execute_result","data":{"text/plain":["[('학생', 'Noun'),\n"," ('들', 'Suffix'),\n"," ('부터', 'Josa'),\n"," ('많이', 'Adverb'),\n"," ('잡혀', 'Verb'),\n"," ('들어갔다', 'Verb')]"]},"metadata":{},"execution_count":4}],"source":["sentence = '''절망의 반대가 희망은 아니다.\n","어두운 밤하늘에 별이 빛나듯\n","희망은 절망 속에 싹트는 거지\n","만약에 우리가 희망함이 적다면\n","그 누가 세상을 비출어줄까.\n","정희성, 희망 공부'''\n","\n","print('형태소:', Okt.morphs(sentence))\n","print()\n","print('명사:', Okt.nouns(sentence))\n","print()\n","print('품사 태깅 결과:', Okt.pos(sentence))\n","\n","sentence = \"강아지가 아파서 약을 먹이다.\"\n","print(Okt.pos(sentence))\n","\n","sentence = \"학생들부터 많이 잡혀 들어갔다\"\n","Okt.pos(sentence)\n"]},{"cell_type":"markdown","metadata":{"id":"x4AdGlxWCuy0"},"source":["## 한국어 형태소 분석"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MogqoYuVCuy0","outputId":"08cac14a-afe7-4674-b472-776b1300735c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('죽는', 'Verb'), ('날', 'Noun'), ('까지', 'Josa'), ('하늘', 'Noun'), ('을', 'Josa'), ('우러러', 'Noun'), ('한', 'Verb'), ('점', 'Noun'), ('부끄럼', 'Noun'), ('이', 'Josa'), ('없기를', 'Adjective'), (',', 'Punctuation'), ('잎새', 'Noun'), ('에', 'Josa'), ('이는', 'Verb'), ('바람', 'Noun'), ('에도', 'Josa'), ('나', 'Noun'), ('는', 'Josa'), ('괴로워', 'Adjective'), ('했다', 'Verb'), ('.', 'Punctuation')]\n"]}],"source":["# from konlpy.tag import Twitter\n","from konlpy.tag import Okt\n","\n","# twitter = Twitter()\n","twitter = Okt()\n","\n","text = \"죽는 날까지 하늘을 우러러 한 점 부끄럼이 없기를, 잎새에 이는 바람에도 나는 괴로워했다.\"\n","\n","text_pos = twitter.pos(text) # Twitter 모듈안에 있는 pos 사용자 함수를 호출\n","print(text_pos) # 리스트 내 튜플 형태(단어, 품사)로 출력 값 생성\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NosxXkNhCuy0","outputId":"796a87e8-70dd-422d-b7ca-877be829dc12"},"outputs":[{"name":"stdout","output_type":"stream","text":["죽는\tVerb\n","날\tNoun\n","까지\tJosa\n","하늘\tNoun\n","을\tJosa\n","우러러\tNoun\n","한\tVerb\n","점\tNoun\n","부끄럼\tNoun\n","이\tJosa\n","없기를\tAdjective\n",",\tPunctuation\n","잎새\tNoun\n","에\tJosa\n","이는\tVerb\n","바람\tNoun\n","에도\tJosa\n","나\tNoun\n","는\tJosa\n","괴로워\tAdjective\n","했다\tVerb\n",".\tPunctuation\n"]}],"source":["for word, pos in text_pos:\n","    print(\"{}\\t{}\".format(word, pos))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJe8sCxBCuy0","outputId":"9d3ee80f-fab2-46d8-f31f-c9d6dcfba2b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('죽는', 'Verb'), ('날', 'Noun'), ('까지', 'Josa'), ('하늘', 'Noun'), ('을', 'Josa'), ('우러러', 'Noun'), ('한', 'Verb'), ('점', 'Noun'), ('부끄럼', 'Noun'), ('이', 'Josa'), ('없기를', 'Adjective'), (',', 'Punctuation'), ('잎새', 'Noun'), ('에', 'Josa'), ('이는', 'Verb'), ('바람', 'Noun'), ('에도', 'Josa'), ('나', 'Noun'), ('는', 'Josa'), ('괴로워', 'Adjective'), ('했다', 'Verb'), ('.', 'Punctuation')] \n","\n","[('죽다', 'Verb'), ('날', 'Noun'), ('까지', 'Josa'), ('하늘', 'Noun'), ('을', 'Josa'), ('우러러', 'Noun'), ('하다', 'Verb'), ('점', 'Noun'), ('부끄럼', 'Noun'), ('이', 'Josa'), ('없다', 'Adjective'), (',', 'Punctuation'), ('잎새', 'Noun'), ('에', 'Josa'), ('이다', 'Verb'), ('바람', 'Noun'), ('에도', 'Josa'), ('나', 'Noun'), ('는', 'Josa'), ('괴롭다', 'Adjective'), ('하다', 'Verb'), ('.', 'Punctuation')] \n","\n","[('죽다', 'Verb'), ('날', 'Noun'), ('까지', 'Josa'), ('하늘', 'Noun'), ('을', 'Josa'), ('우러러', 'Noun'), ('하다', 'Verb'), ('점', 'Noun'), ('부끄럼', 'Noun'), ('이', 'Josa'), ('없다', 'Adjective'), (',', 'Punctuation'), ('잎새', 'Noun'), ('에', 'Josa'), ('이다', 'Verb'), ('바람', 'Noun'), ('에도', 'Josa'), ('나', 'Noun'), ('는', 'Josa'), ('괴롭다', 'Adjective'), ('하다', 'Verb'), ('.', 'Punctuation')] \n","\n"]}],"source":["from konlpy.tag import Okt\n","\n","twitter = Okt()\n","\n","text = \"죽는 날까지 하늘을 우러러 한 점 부끄럼이 없기를, 잎새에 이는 바람에도 나는 괴로워했다.\"\n","# text = \"죽는 날까지 하늘을 우러러 한 점 부끄림이 없기를, 잎새에 이는 바람에도 나는 괴로워했다.\"\n","\n","text_pos = twitter.pos(text, norm=True, stem=False) # norm: 오타를 정규화해준다고 하나 성능이 별로...\n","print(text_pos, \"\\n\")\n","\n","text_pos = twitter.pos(text, norm=False, stem=True) # stem: 했다' => \"하다\"\n","print(text_pos, \"\\n\")\n","\n","text_pos = twitter.pos(text, norm=True, stem=True)\n","print(text_pos, \"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"1PpTGHa6Cuy0"},"source":["## 튜플의 자동 언패킹(unpacking) 기능 활용법\n","\n","리스트의 원소인 튜플을 하나씩 접근한 후, 개별 튜플의 원소들을 각각 출력하기 위해서는 다음과 같이 for문을 사용하면 된다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mbPAP3SfCuy0","outputId":"47158638-85de-41cd-bce5-484d4302850f"},"outputs":[{"name":"stdout","output_type":"stream","text":["a 1\n","b 2\n","c 3\n","d 4\n","e 5\n"]}],"source":["A = [('a', 1), ('b', 2), ('c', 3), ('d', 4), ('e', 5)]\n","\n","for i in A:\n","    print(i[0], i[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4etOuiQCuy0","outputId":"f3db5d7b-442e-4c18-e1fc-085ca3b59d03"},"outputs":[{"name":"stdout","output_type":"stream","text":["a 1\n","b 2\n","c 3\n","d 4\n","e 5\n"]}],"source":["for first, second in A:\n","    print(first, second)"]},{"cell_type":"markdown","metadata":{"id":"i5Ry3izDCuy0"},"source":["이번엔 `morphs() 메소드`와 `nouns() 메소드`를 적용해 보면, 결과에서 보듯 문장에서 분절된 형태소와 분절된 형태소들 가운데 명사만을 각각 리스트 내 원소로 반환해 준다. (텍스트 분석에서 가장 많이 사용되는 품사가 명사이기 때문에 명사만 따로 메소드 있음)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHks2vi0Cuy0","outputId":"07266436-ad81-402e-c21d-ec744441f760"},"outputs":[{"name":"stdout","output_type":"stream","text":["['죽는', '날', '까지', '하늘', '을', '우러러', '한', '점', '부끄럼', '이', '없기를', ',', '잎새', '에', '이는', '바람', '에도', '나', '는', '괴로워', '했다', '.']\n"]}],"source":["text = \"죽는 날까지 하늘을 우러러 한 점 부끄럼이 없기를, 잎새에 이는 바람에도 나는 괴로워했다.\"\n","\n","text_words = twitter.morphs(text)\n","\n","print(text_words)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Xe-c0I4Cuy0","outputId":"f39407da-5a68-4569-c59f-fd7da99e6b59"},"outputs":[{"name":"stdout","output_type":"stream","text":["['날', '하늘', '우러러', '점', '부끄럼', '잎새', '바람', '나']\n"]}],"source":["text = \"죽는 날까지 하늘을 우러러 한 점 부끄럼이 없기를, 잎새에 이는 바람에도 나는 괴로워했다.\"\n","\n","text_nouns = twitter.nouns(text)\n","\n","print(text_nouns)"]},{"cell_type":"markdown","metadata":{"id":"Y13KA2OyCuy1"},"source":["### (1) 텍스트를 셀 내에서 직접 입력한 후 형태소분석 수행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rxsDsRmvCuy1","outputId":"8e121ffc-6138-43d1-b2c7-fe2ad2de94b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["a1:  ['이', '화', '여', '자', '대', '학', '교']\n","a2:  ['이', '화', '여', '자', '대', '학', '교']\n"]}],"source":["a= \"이 화 여 자 대 학 교\"\n","a1= a.split(\" \")\n","\n","print(\"a1: \", a1)\n","\n","a2 =[]\n","\n","for word in a1:\n","#    print(word)\n","#     a2.append(word)\n","    a2 += word\n","\n","print(\"a2: \", a2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hEhFe347Cuy1","outputId":"e6ba78a2-c9c5-45f8-93ee-31f96903af3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[(\"'\", 'SS'), ('눈', 'NNG'), ('이', 'JKS'), ('부시', 'VA'), ('게', 'ECD'), (\"'\", 'SS'), ('가', 'VV'), ('아', 'ECS'), ('가뿐', 'XR'), ('하', 'XSA'), ('게', 'ECD'), ('지상파', 'NNG'), ('월화', 'NNG'), ('극', 'NNG'), ('을', 'JKO'), ('따돌리', 'VV'), ('며', 'ECE'), ('6', 'NR'), ('%', 'SW'), ('를', 'JKO'), ('돌파', 'NNG'), ('하', 'XSV'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF')], [], [('27', 'NR'), ('일', 'NNM'), ('시청률', 'NNG'), ('조사', 'NNG'), ('회사', 'NNG'), ('니', 'VV'), ('ㄹ', 'ETD'), ('스', 'VV'), ('ㄴ', 'ETD'), ('코리아', 'NNG'), ('에', 'JKM'), ('따르', 'VV'), ('면', 'ECE'), ('26', 'NR'), ('일', 'NNM'), ('방송', 'NNG'), ('되', 'XSV'), ('ㄴ', 'ETD'), ('JTBC', 'OL'), ('월화', 'NNG'), ('극', 'NNG'), (\"'\", 'SS'), ('눈', 'NNG'), ('이', 'JKS'), ('부시', 'VA'), ('게', 'ECD'), (\"'\", 'SS'), ('늘', 'VV'), ('ㄴ', 'ETD'), ('6.567', 'NR'), ('%', 'SW'), ('(', 'SS'), ('전국', 'NNG'), ('유료', 'NNG'), ('가구', 'NNG'), ('기준', 'NNG'), (')', 'SS'), ('의', 'NNG'), ('시청률', 'NNG'), ('을', 'JKO'), ('기록', 'NNG'), ('?', 'SF')], [('5', 'NR'), ('회', 'NNM'), ('연속', 'NNG'), ('자체', 'NNG'), ('최고', 'NNG'), ('시청률', 'NNG'), ('을', 'JKO'), ('찍', 'VV'), ('으며', 'ECE'), ('멈추', 'VV'), ('ㄹ', 'ETD'), ('줄', 'NNB'), ('모르', 'VV'), ('는', 'ETD'), ('상승세', 'NNG'), ('를', 'JKO'), ('잇', 'VV'), ('어', 'ECD'), ('가', 'VV'), ('고', 'ECE'), ('있', 'VXV'), ('다', 'EFN'), ('!', 'SF')], [('동시', 'NNG'), ('에', 'JKM'), ('첫', 'MDT'), ('6', 'NR'), ('%', 'SW'), ('대', 'NNB'), ('돌파', 'NNG'), ('이', 'VCP'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF')], [('동', 'NNG'), ('시간대', 'NNG'), ('방송', 'NNG'), ('되', 'XSV'), ('ㄴ', 'ETD'), ('지상파', 'NNG'), ('3', 'NR'), ('사', 'NR'), ('월', 'NNM'), ('화극', 'NNG'), ('SBS', 'OL'), (\"'\", 'SS'), ('해치', 'NNG'), (\"'\", 'SS'), ('KBS', 'OL'), ('2', 'NR'), ('TV', 'OL'), (\"'\", 'SS'), ('동네', 'NNG'), ('변호사', 'NNG'), ('조', 'NNG'), ('들', 'XSN'), ('호', 'NNB'), ('2', 'NR'), (':', 'SP'), ('죄', 'NNG'), ('와', 'JC'), ('벌', 'NNG'), (\"'\", 'SS'), ('MBC', 'OL'), (\"'\", 'SS'), ('아이템', 'NNG'), (\"'\", 'SS'), ('을', 'NNG'), ('따돌리', 'VV'), ('고', 'ECE'), ('우위', 'NNG'), ('를', 'JKO'), ('점하', 'VV'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF')], [('tvN', 'OL'), (\"'\", 'SS'), ('왕', 'NNG'), ('이', 'JKC'), ('되', 'VV'), ('ㄴ', 'ETD'), ('남자', 'NNG'), (\"'\", 'SS'), ('(', 'SS'), ('9.5', 'NR'), ('%', 'SW'), (')', 'SS'), ('를', 'JKO'), ('잇', 'VV'), ('는', 'ETD'), ('월화', 'NNG'), ('극', 'NNG'), ('전체', 'NNG'), ('2', 'NR'), ('위', 'NNM'), ('에', 'JKM'), ('이름', 'NNG'), ('을', 'JKO'), ('올리', 'VV'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF')], [(\"'\", 'SS'), ('왕', 'NNG'), ('이', 'JKC'), ('되', 'VV'), ('ㄴ', 'ETD'), ('남자', 'NNG'), (\"'\", 'SS'), ('의', 'NNG'), ('경우', 'NNG'), ('종영', 'NNG'), ('을', 'JKO'), ('앞두', 'VV'), ('고', 'ECE'), ('있', 'VXV'), ('기에', 'ECD'), (\"'\", 'SS'), ('눈', 'NNG'), ('이', 'JKS'), ('부시', 'VA'), ('게', 'ECD'), (\"'\", 'SS'), ('가', 'VV'), ('아', 'ECS'), ('어디', 'NP'), ('까지', 'JX'), ('상승', 'NNG'), ('하', 'XSV'), ('ㄹ', 'ETD'), ('수', 'NNB'), ('있', 'VV'), ('을지', 'ECS'), ('주목', 'NNG'), ('되', 'XSV'), ('ㄴ다', 'EFN'), ('!', 'SF')], [], [('이날', 'NNG'), ('방송', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('김', 'NNG'), ('혜', 'UN'), ('자', 'NNG'), ('(', 'SS'), ('김', 'NNG'), ('혜', 'UN'), ('자', 'NNG'), (')', 'SS'), ('가', 'NNG'), ('방송', 'NNG'), ('말미', 'NNG'), ('시간', 'NNG'), ('을', 'JKO'), ('되돌리', 'VV'), ('는', 'ETD'), ('시계', 'NNG'), ('를', 'JKO'), ('발견', 'NNG'), ('하', 'XSV'), ('는', 'ETD'), ('모습', 'NNG'), ('이', 'JKS'), ('그려지', 'VV'), ('었', 'EPT'), ('다', 'EFN'), ('?', 'SF')], [('전무', 'NNG'), ('송', 'NNG'), ('이', 'JKS'), ('이', 'MDT'), ('시계', 'NNG'), ('를', 'JKO'), ('차', 'VV'), ('고', 'ECE'), ('있었', 'VV'), ('고', 'ECE'), ('시계', 'NNG'), ('를', 'JKO'), ('보', 'VV'), ('ㄴ', 'ETD'), ('후', 'NNG'), ('눈빛', 'NNG'), ('이', 'JKS'), ('심하', 'VA'), ('게', 'ECD'), ('흔들리', 'VV'), ('ㄴ', 'ETD'), ('김혜자', 'UN'), ('의', 'JKG'), ('모습', 'NNG'), ('을', 'JKO'), ('통하', 'VV'), ('어', 'ECS'), ('다시금', 'MAG'), ('시간', 'NNG'), ('을', 'JKO'), ('되돌리', 'VV'), ('ㄹ', 'ETD'), ('수', 'NNB'), ('있', 'VV'), ('을지', 'ECS'), ('여부', 'NNG'), ('에', 'JKM'), ('관심', 'NNG'), ('이', 'JKS'), ('쏠리', 'VV'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF')]]\n"]}],"source":["from konlpy.tag import Kkma\n","\n","def split_sentences(text):\n","    text = text.strip().replace(\". \", \".\\n\").replace(\"? \", \"?\\n\").replace(\"! \", \"!\\n\")\n","    sentences = text.splitlines()\n","\n","    return sentences\n","\n","\n","def get_pos(analyzer, text):\n","\n","    morph_anals = []\n","    sentences = split_sentences(text)                       # 형태소분석 전에 문장 단위로 분리. 위에서 정의한 split_sentences 호출\n","\n","    for sentence in sentences:\n","        morph_anal = analyzer.pos(sentence)                 # 문장 단위로 형태소 분석하여 morph_anal의 출력 값 = [(word, pos)]\n","        morph_anals.append(morph_anal)\n","\n","    return morph_anals\n","\n","# main\n","\n","textdata = \"\"\"\n","'눈이 부시게'가 가뿐하게 지상파 월화극을 따돌리며 6%를 돌파했다.\n","27일 시청률 조사회사 닐슨 코리아에 따르면 26일 방송된 JTBC 월화극 '눈이 부시게'는 6.567%(전국 유료가구 기준)의 시청률을 기록? 5회 연속 자체 최고 시청률을 찍으며 멈출 줄 모르는 상승세를 이어가고 있다!\n","동시에 첫 6%대 돌파였다. 동 시간대 방송된 지상파 3사 월화극 SBS '해치' KBS 2TV '동네변호사 조들호2:죄와 벌' MBC '아이템'을 따돌리고 우위를 점했다. tvN '왕이 된 남자'(9.5%)를 잇는 월화극 전체 2위에 이름을 올렸다. '왕이 된 남자'의 경우 종영을 앞두고 있기에 '눈이 부시게'가 어디까지 상승할 수 있을지 주목된다!\n","이날 방송에는 김혜자(김혜자)가 방송 말미 시간을 되돌리는 시계를 발견하는 모습이 그려졌다? 전무송이 이 시계를 차고 있었고 시계를 본 후 눈빛이 심하게 흔들린 김혜자의 모습을 통해 다시금 시간을 되돌릴 수 있을지 여부에 관심이 쏠렸다.\n","\"\"\"\n","\n","kkma = Kkma()\n","textdata_pos = get_pos(kkma, textdata)\n","print(textdata_pos)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qb1YvEaqCuy1","outputId":"e8da7528-52f9-4525-be30-e07f38f40cfb"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6.0\n"]}],"source":["import konlpy\n","\n","print(konlpy.__version__)\n"]},{"cell_type":"markdown","metadata":{"id":"rK3cTWcbCuy1"},"source":["### (2) 외부 텍스트 파일을 불러와 형태소분석 수행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIezMDE6Cuy1","outputId":"1f91f26a-384e-43b0-c1a2-a63956b8a449"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[(\"'\", 'Punctuation'), ('눈', 'Noun'), ('이', 'Josa'), ('부시', 'Noun'), ('게', 'Josa'), (\"'\", 'Punctuation'), ('가', 'Verb'), ('가뿐하게', 'Adjective'), ('지상파', 'Noun'), ('월화', 'Noun'), ('극', 'Suffix'), ('을', 'Josa'), ('따돌리며', 'Verb'), ('6%', 'Number'), ('를', 'Noun'), ('돌파', 'Noun'), ('했다', 'Verb'), ('.', 'Punctuation')]], [[('27일', 'Number'), ('시청률', 'Noun'), ('조사', 'Noun'), ('회사', 'Noun'), ('닐슨', 'Noun'), ('코리아', 'Noun'), ('에', 'Josa'), ('따르면', 'Verb'), ('26일', 'Number'), ('방송', 'Noun'), ('된', 'Verb'), ('JTBC', 'Alpha'), ('월화', 'Noun'), ('극', 'Suffix'), (\"'\", 'Punctuation'), ('눈', 'Noun'), ('이', 'Josa'), ('부시', 'Noun'), ('게', 'Josa'), (\"'\", 'Punctuation'), ('는', 'Verb'), ('6.567%', 'Number'), ('(', 'Foreign'), ('전국', 'Noun'), ('유료', 'Noun'), ('가구', 'Noun'), ('기준', 'Noun'), (')', 'Punctuation'), ('의', 'Noun'), ('시청률', 'Noun'), ('을', 'Josa'), ('기록', 'Noun'), ('했다', 'Verb'), ('.', 'Punctuation')]], [[('5회', 'Number'), ('연속', 'Noun'), ('자체', 'Noun'), ('최고', 'Noun'), ('시청률', 'Noun'), ('을', 'Josa'), ('찍으며', 'Verb'), ('멈출', 'Verb'), ('줄', 'Noun'), ('모르는', 'Verb'), ('상승세', 'Noun'), ('를', 'Josa'), ('이', 'Determiner'), ('어가', 'Noun'), ('고', 'Josa'), ('있다', 'Adjective'), ('.', 'Punctuation')], [('동시', 'Noun'), ('에', 'Josa'), ('첫', 'Noun'), ('6%', 'Number'), ('대', 'Verb'), ('돌파', 'Noun'), ('였다', 'Verb'), ('.', 'Punctuation')]], [[('동', 'Modifier'), ('시간대', 'Noun'), ('방송', 'Noun'), ('된', 'Verb'), ('지상파', 'Noun'), ('3', 'Number'), ('사', 'Noun'), ('월화', 'Noun'), ('극', 'Suffix'), ('SBS', 'Alpha'), (\"'\", 'Punctuation'), ('해치', 'Noun'), (\"'\", 'Punctuation'), ('KBS', 'Alpha'), ('2', 'Number'), ('TV', 'Alpha'), (\"'\", 'Punctuation'), ('동네', 'Noun'), ('변호사', 'Noun'), ('조', 'Noun'), ('들', 'Suffix'), ('호', 'Noun'), ('2', 'Number'), (':', 'Punctuation'), ('죄', 'Noun'), ('와', 'Josa'), ('벌', 'Noun'), (\"'\", 'Punctuation'), ('MBC', 'Alpha'), (\"'\", 'Punctuation'), ('아이템', 'Noun'), (\"'\", 'Punctuation'), ('을', 'Josa'), ('따돌리고', 'Verb'), ('우위', 'Noun'), ('를', 'Josa'), ('점', 'Noun'), ('했다', 'Verb'), ('.', 'Punctuation')]], [[('tvN', 'Alpha'), (\"'\", 'Punctuation'), ('왕', 'Noun'), ('이', 'Josa'), ('된', 'Verb'), ('남자', 'Noun'), (\"'(\", 'Punctuation'), ('9.5%', 'Number'), (')', 'Foreign'), ('를', 'Noun'), ('잇는', 'Verb'), ('월화', 'Noun'), ('극', 'Suffix'), ('전체', 'Noun'), ('2', 'Number'), ('위', 'Noun'), ('에', 'Josa'), ('이름', 'Noun'), ('을', 'Josa'), ('올렸다', 'Verb'), ('.', 'Punctuation')], [(\"'\", 'Punctuation'), ('왕', 'Noun'), ('이', 'Josa'), ('된', 'Verb'), ('남자', 'Noun'), (\"'\", 'Punctuation'), ('의', 'Noun'), ('경우', 'Noun'), ('종영', 'Noun'), ('을', 'Josa'), ('앞두고', 'Verb'), ('있기에', 'Adjective'), (\"'\", 'Punctuation'), ('눈', 'Noun'), ('이', 'Josa'), ('부시', 'Noun'), ('게', 'Josa'), (\"'\", 'Punctuation'), ('가', 'Verb'), ('어디', 'Noun'), ('까지', 'Josa'), ('상승', 'Noun'), ('할', 'Verb'), ('수', 'Noun'), ('있을지', 'Adjective'), ('주목', 'Noun'), ('된다', 'Verb'), ('.', 'Punctuation')]], [[('이', 'Determiner'), ('날', 'Noun'), ('방송', 'Noun'), ('에는', 'Josa'), ('김혜자', 'Noun'), ('(', 'Punctuation'), ('김혜자', 'Noun'), (')', 'Punctuation'), ('가', 'Verb'), ('방송', 'Noun'), ('말미', 'Noun'), ('시간', 'Noun'), ('을', 'Josa'), ('되돌리는', 'Verb'), ('시계', 'Noun'), ('를', 'Josa'), ('발견', 'Noun'), ('하는', 'Verb'), ('모습', 'Noun'), ('이', 'Josa'), ('그려졌다', 'Verb'), ('.', 'Punctuation')], [('전무송', 'Noun'), ('이', 'Josa'), ('이', 'Noun'), ('시계', 'Noun'), ('를', 'Josa'), ('차고', 'Noun'), ('있었고', 'Adjective'), ('시계', 'Noun'), ('를', 'Josa'), ('본', 'Verb'), ('후', 'Noun'), ('눈빛', 'Noun'), ('이', 'Josa'), ('심하게', 'Adjective'), ('흔들린', 'Verb'), ('김혜자', 'Noun'), ('의', 'Josa'), ('모습', 'Noun'), ('을', 'Josa'), ('통해', 'Noun'), ('다시금', 'Noun'), ('시간', 'Noun'), ('을', 'Josa'), ('되돌릴', 'Verb'), ('수', 'Noun'), ('있을지', 'Adjective'), ('여부', 'Noun'), ('에', 'Josa'), ('관심', 'Noun'), ('이', 'Josa'), ('쏠렸다', 'Verb'), ('.', 'Punctuation')]]]\n","\n","[[[(\"'\", 'Punctuation'), ('눈', 'Noun'), ('이', 'Josa'), ('부시', 'Noun'), ('게', 'Josa'), (\"'\", 'Punctuation'), ('가', 'Verb'), ('가뿐하게', 'Adjective'), ('지상파', 'Noun'), ('월화', 'Noun'), ('극', 'Suffix'), ('을', 'Josa'), ('따돌리며', 'Verb'), ('6%', 'Number'), ('를', 'Noun'), ('돌파', 'Noun'), ('했다', 'Verb'), ('.', 'Punctuation')]], [[('27일', 'Number'), ('시청률', 'Noun'), ('조사', 'Noun'), ('회사', 'Noun'), ('닐슨', 'Noun'), ('코리아', 'Noun'), ('에', 'Josa'), ('따르면', 'Verb'), ('26일', 'Number'), ('방송', 'Noun'), ('된', 'Verb'), ('JTBC', 'Alpha'), ('월화', 'Noun'), ('극', 'Suffix'), (\"'\", 'Punctuation'), ('눈', 'Noun'), ('이', 'Josa'), ('부시', 'Noun'), ('게', 'Josa'), (\"'\", 'Punctuation'), ('는', 'Verb'), ('6.567%', 'Number'), ('(', 'Foreign'), ('전국', 'Noun'), ('유료', 'Noun'), ('가구', 'Noun'), ('기준', 'Noun'), (')', 'Punctuation'), ('의', 'Noun'), ('시청률', 'Noun'), ('을', 'Josa'), ('기록', 'Noun'), ('했다', 'Verb'), ('.', 'Punctuation')]], [[('5회', 'Number'), ('연속', 'Noun'), ('자체', 'Noun'), ('최고', 'Noun'), ('시청률', 'Noun'), ('을', 'Josa'), ('찍으며', 'Verb'), ('멈출', 'Verb'), ('줄', 'Noun'), ('모르는', 'Verb'), ('상승세', 'Noun'), ('를', 'Josa'), ('이', 'Determiner'), ('어가', 'Noun'), ('고', 'Josa'), ('있다', 'Adjective'), ('.', 'Punctuation')], [('동시', 'Noun'), ('에', 'Josa'), ('첫', 'Noun'), ('6%', 'Number'), ('대', 'Verb'), ('돌파', 'Noun'), ('였다', 'Verb'), ('.', 'Punctuation')]], [[('동', 'Modifier'), ('시간대', 'Noun'), ('방송', 'Noun'), ('된', 'Verb'), ('지상파', 'Noun'), ('3', 'Number'), ('사', 'Noun'), ('월화', 'Noun'), ('극', 'Suffix'), ('SBS', 'Alpha'), (\"'\", 'Punctuation'), ('해치', 'Noun'), (\"'\", 'Punctuation'), ('KBS', 'Alpha'), ('2', 'Number'), ('TV', 'Alpha'), (\"'\", 'Punctuation'), ('동네', 'Noun'), ('변호사', 'Noun'), ('조', 'Noun'), ('들', 'Suffix'), ('호', 'Noun'), ('2', 'Number'), (':', 'Punctuation'), ('죄', 'Noun'), ('와', 'Josa'), ('벌', 'Noun'), (\"'\", 'Punctuation'), ('MBC', 'Alpha'), (\"'\", 'Punctuation'), ('아이템', 'Noun'), (\"'\", 'Punctuation'), ('을', 'Josa'), ('따돌리고', 'Verb'), ('우위', 'Noun'), ('를', 'Josa'), ('점', 'Noun'), ('했다', 'Verb'), ('.', 'Punctuation')]], [[('tvN', 'Alpha'), (\"'\", 'Punctuation'), ('왕', 'Noun'), ('이', 'Josa'), ('된', 'Verb'), ('남자', 'Noun'), (\"'(\", 'Punctuation'), ('9.5%', 'Number'), (')', 'Foreign'), ('를', 'Noun'), ('잇는', 'Verb'), ('월화', 'Noun'), ('극', 'Suffix'), ('전체', 'Noun'), ('2', 'Number'), ('위', 'Noun'), ('에', 'Josa'), ('이름', 'Noun'), ('을', 'Josa'), ('올렸다', 'Verb'), ('.', 'Punctuation')], [(\"'\", 'Punctuation'), ('왕', 'Noun'), ('이', 'Josa'), ('된', 'Verb'), ('남자', 'Noun'), (\"'\", 'Punctuation'), ('의', 'Noun'), ('경우', 'Noun'), ('종영', 'Noun'), ('을', 'Josa'), ('앞두고', 'Verb'), ('있기에', 'Adjective'), (\"'\", 'Punctuation'), ('눈', 'Noun'), ('이', 'Josa'), ('부시', 'Noun'), ('게', 'Josa'), (\"'\", 'Punctuation'), ('가', 'Verb'), ('어디', 'Noun'), ('까지', 'Josa'), ('상승', 'Noun'), ('할', 'Verb'), ('수', 'Noun'), ('있을지', 'Adjective'), ('주목', 'Noun'), ('된다', 'Verb'), ('.', 'Punctuation')]], [[('이', 'Determiner'), ('날', 'Noun'), ('방송', 'Noun'), ('에는', 'Josa'), ('김혜자', 'Noun'), ('(', 'Punctuation'), ('김혜자', 'Noun'), (')', 'Punctuation'), ('가', 'Verb'), ('방송', 'Noun'), ('말미', 'Noun'), ('시간', 'Noun'), ('을', 'Josa'), ('되돌리는', 'Verb'), ('시계', 'Noun'), ('를', 'Josa'), ('발견', 'Noun'), ('하는', 'Verb'), ('모습', 'Noun'), ('이', 'Josa'), ('그려졌다', 'Verb'), ('.', 'Punctuation')], [('전무송', 'Noun'), ('이', 'Josa'), ('이', 'Noun'), ('시계', 'Noun'), ('를', 'Josa'), ('차고', 'Noun'), ('있었고', 'Adjective'), ('시계', 'Noun'), ('를', 'Josa'), ('본', 'Verb'), ('후', 'Noun'), ('눈빛', 'Noun'), ('이', 'Josa'), ('심하게', 'Adjective'), ('흔들린', 'Verb'), ('김혜자', 'Noun'), ('의', 'Josa'), ('모습', 'Noun'), ('을', 'Josa'), ('통해', 'Noun'), ('다시금', 'Noun'), ('시간', 'Noun'), ('을', 'Josa'), ('되돌릴', 'Verb'), ('수', 'Noun'), ('있을지', 'Adjective'), ('여부', 'Noun'), ('에', 'Josa'), ('관심', 'Noun'), ('이', 'Josa'), ('쏠렸다', 'Verb'), ('.', 'Punctuation')]]]\n"]}],"source":["# from konlpy.tag import Twitter\n","from konlpy.tag import Okt\n","\n","def split_sentences(text):\n","    text = text.strip().replace(\". \", \".\\n\").replace(\"? \", \"?\\n\").replace(\"! \", \"!\\n\")\n","    sentences = text.splitlines()\n","\n","    return sentences\n","\n","\n","def get_pos(analyzer, text):\n","\n","    morph_anals = []\n","    sentences = split_sentences(text)                       # 형태소분석 전에 문장 단위로 분리. 위 함수 split_sentences 호출\n","\n","    for sentence in sentences:\n","        morph_anal = analyzer.pos(sentence)            # 문장 단위로 형태소분석하여 word와 pos를 출력\n","        morph_anals.append(morph_anal)\n","\n","    return morph_anals\n","\n","\n","\n","# main\n","\n","input_file_name = r\".\\Data\\textdata.txt\"\n","\n","# twitter = Twitter()\n","twitter = Okt()\n","\n","\n","textdata_pos = []\n","\n","with open(input_file_name, \"r\", encoding=\"EUC-KR\") as input_file:\n","    for line in input_file:\n","        words_pos = get_pos(twitter, line)  # 앞서 정의한 사용자 함수 def split_sentences를 호출해 매개변수에 line을 입력\n","        textdata_pos.append(words_pos)\n","\n","print(textdata_pos)\n","\n","\n","import pickle\n","\n","# 형태소분석 결과 파일 저장\n","f = open('test_morphs.txt', 'wb')\n","pickle.dump(textdata_pos, f)\n","f.close()\n","\n","print()\n","\n","# 파일에서 읽어올 때\n","f = open('test_morphs.txt', 'rb')\n","textdata_pos = pickle.load(f)\n","print(textdata_pos)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"xVNSG94GCuy1","outputId":"f3602625-8ef1-4db4-f938-6852a30bb2fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["품사 태깅 결과: [(\"'\", 'Punctuation'), ('눈', 'Noun'), ('이', 'Josa'), ('부시', 'Noun'), ('게', 'Josa'), (\"'\", 'Punctuation'), ('가', 'Verb'), ('가뿐하게', 'Adjective'), ('지상파', 'Noun'), ('월화', 'Noun'), ('극', 'Suffix'), ('을', 'Josa'), ('따돌리며', 'Verb'), ('6%', 'Number'), ('를', 'Noun'), ('돌파', 'Noun'), ('했다', 'Verb'), ('.', 'Punctuation'), ('\\n', 'Foreign'), ('27일', 'Number'), ('시청률', 'Noun'), ('조사', 'Noun'), ('회사', 'Noun'), ('닐슨', 'Noun'), ('코리아', 'Noun'), ('에', 'Josa'), ('따르면', 'Verb'), ('26일', 'Number'), ('방송', 'Noun'), ('된', 'Verb'), ('JTBC', 'Alpha'), ('월화', 'Noun'), ('극', 'Suffix'), (\"'\", 'Punctuation'), ('눈', 'Noun'), ('이', 'Josa'), ('부시', 'Noun'), ('게', 'Josa'), (\"'\", 'Punctuation'), ('는', 'Verb'), ('6.567%', 'Number'), ('(', 'Foreign'), ('전국', 'Noun'), ('유료', 'Noun'), ('가구', 'Noun'), ('기준', 'Noun'), (')', 'Punctuation'), ('의', 'Noun'), ('시청률', 'Noun'), ('을', 'Josa'), ('기록', 'Noun'), ('했다', 'Verb'), ('.', 'Punctuation'), ('5회', 'Number'), ('연속', 'Noun'), ('자체', 'Noun'), ('최고', 'Noun'), ('시청률', 'Noun'), ('을', 'Josa'), ('찍으며', 'Verb'), ('멈출', 'Verb'), ('줄', 'Noun'), ('모르는', 'Verb'), ('상승세', 'Noun'), ('를', 'Josa'), ('이', 'Determiner'), ('어가', 'Noun'), ('고', 'Josa'), ('있다', 'Adjective'), ('.', 'Punctuation'), ('동시', 'Noun'), ('에', 'Josa'), ('첫', 'Noun'), ('6%', 'Number'), ('대', 'Verb'), ('돌파', 'Noun'), ('였다', 'Verb'), ('.', 'Punctuation'), ('동', 'Modifier'), ('시간대', 'Noun'), ('방송', 'Noun'), ('된', 'Verb'), ('지상파', 'Noun'), ('3', 'Number'), ('사', 'Noun'), ('월화', 'Noun'), ('극', 'Suffix'), ('SBS', 'Alpha'), (\"'\", 'Punctuation'), ('해치', 'Noun'), (\"'\", 'Punctuation'), ('KBS', 'Alpha'), ('2', 'Number'), ('TV', 'Alpha'), (\"'\", 'Punctuation'), ('동네', 'Noun'), ('변호사', 'Noun'), ('조', 'Noun'), ('들', 'Suffix'), ('호', 'Noun'), ('2', 'Number'), (':', 'Punctuation'), ('죄', 'Noun'), ('와', 'Josa'), ('벌', 'Noun'), (\"'\", 'Punctuation'), ('MBC', 'Alpha'), (\"'\", 'Punctuation'), ('아이템', 'Noun'), (\"'\", 'Punctuation'), ('을', 'Josa'), ('따돌리고', 'Verb'), ('우위', 'Noun'), ('를', 'Josa'), ('점', 'Noun'), ('했다', 'Verb'), ('.', 'Punctuation'), ('tvN', 'Alpha'), (\"'\", 'Punctuation'), ('왕', 'Noun'), ('이', 'Josa'), ('된', 'Verb'), ('남자', 'Noun'), (\"'(\", 'Punctuation'), ('9.5%', 'Number'), (')', 'Foreign'), ('를', 'Noun'), ('잇는', 'Verb'), ('월화', 'Noun'), ('극', 'Suffix'), ('전체', 'Noun'), ('2', 'Number'), ('위', 'Noun'), ('에', 'Josa'), ('이름', 'Noun'), ('을', 'Josa'), ('올렸다', 'Verb'), ('.', 'Punctuation'), (\"'\", 'Punctuation'), ('왕', 'Noun'), ('이', 'Josa'), ('된', 'Verb'), ('남자', 'Noun'), (\"'\", 'Punctuation'), ('의', 'Noun'), ('경우', 'Noun'), ('종영', 'Noun'), ('을', 'Josa'), ('앞두고', 'Verb'), ('있기에', 'Adjective'), (\"'\", 'Punctuation'), ('눈', 'Noun'), ('이', 'Josa'), ('부시', 'Noun'), ('게', 'Josa'), (\"'\", 'Punctuation'), ('가', 'Verb'), ('어디', 'Noun'), ('까지', 'Josa'), ('상승', 'Noun'), ('할', 'Verb'), ('수', 'Noun'), ('있을지', 'Adjective'), ('주목', 'Noun'), ('된다', 'Verb'), ('.', 'Punctuation'), ('이', 'Determiner'), ('날', 'Noun'), ('방송', 'Noun'), ('에는', 'Josa'), ('김혜자', 'Noun'), ('(', 'Punctuation'), ('김혜자', 'Noun'), (')', 'Punctuation'), ('가', 'Verb'), ('방송', 'Noun'), ('말미', 'Noun'), ('시간', 'Noun'), ('을', 'Josa'), ('되돌리는', 'Verb'), ('시계', 'Noun'), ('를', 'Josa'), ('발견', 'Noun'), ('하는', 'Verb'), ('모습', 'Noun'), ('이', 'Josa'), ('그려졌다', 'Verb'), ('.', 'Punctuation'), ('전무송', 'Noun'), ('이', 'Josa'), ('이', 'Noun'), ('시계', 'Noun'), ('를', 'Josa'), ('차고', 'Noun'), ('있었고', 'Adjective'), ('시계', 'Noun'), ('를', 'Josa'), ('본', 'Verb'), ('후', 'Noun'), ('눈빛', 'Noun'), ('이', 'Josa'), ('심하게', 'Adjective'), ('흔들린', 'Verb'), ('김혜자', 'Noun'), ('의', 'Josa'), ('모습', 'Noun'), ('을', 'Josa'), ('통해', 'Noun'), ('다시금', 'Noun'), ('시간', 'Noun'), ('을', 'Josa'), ('되돌릴', 'Verb'), ('수', 'Noun'), ('있을지', 'Adjective'), ('여부', 'Noun'), ('에', 'Josa'), ('관심', 'Noun'), ('이', 'Josa'), ('쏠렸다', 'Verb'), ('.', 'Punctuation')]\n"]}],"source":["from konlpy.tag import Okt\n","t = Okt()\n","\n","input_file_name = r\".\\Data\\textdata.txt\"\n","\n","f = open(input_file_name, \"r\", encoding=\"EUC-KR\")\n","\n","print('품사 태깅 결과:', t.pos(f.read()))\n"]},{"cell_type":"markdown","metadata":{"id":"7UtFxKRvCuy1"},"source":["### 참고: 영어 텍스트 분석 라이브러리 spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VaeFlhFwCuy1","outputId":"0ad4d881-80b3-455b-fd31-4477701b1576"},"outputs":[{"name":"stdout","output_type":"stream","text":["['죽는', '날까지', '하늘을', '우러러', '한', '점', '부끄럼이', '없기를', ',', '잎새에', '이는', '바람에도', '나는', '괴로워했다', '.']\n","['죽는 - PROPN', '날까지 - PROPN', '하늘을 - PROPN', '우러러 - PROPN', '한 - ADP', '점 - PROPN', '부끄럼이 - X', '없기를 - INTJ', ', - PUNCT', '잎새에 - NOUN', '이는 - PROPN', '바람에도 - PROPN', '나는 - PROPN', '괴로워했다 - PROPN', '. - PUNCT']\n","Samsung 69 76 ORG\n","South Korea 100 111 GPE\n"]}],"source":["# advanced open source NLP library spacy(advanced NLP techniques, larger volume of text, NLTK와 CoreNLP는 교육 및 연구용)\n","# anaconda prompt 관리자 권한으로 실행. 한글은 지원 안됨\n","# conda install -c conda-forge spacy\n","# python -m spacy download en # default English model (~50MB)   # nlp=spacy.load('en')\n","# python -m spacy download en_core_web_md # larger English model (~1GB) 다운로드함\n","# sm/md/lg (small, medium, large) model, The difference lies in accuracy and loading time.\n","\n","import spacy\n","\n","nlp = spacy.load('en_core_web_md')\n","\n","txt = \"It's an unexpected thing.\"\n","\n","doc = nlp(text)\n","tokens = [token.text for token in doc]\n","print(tokens)\n","\n","# doc = nlp(text)\n","tokens_with_POS = [token.text + \" - \" + token.pos_ for token in doc]\n","print(tokens_with_POS)\n","\n","# NER(Named Entity Recognition)\n","text = \"\"\"Most of the outlay will be at home. No surprise there, either. While Samsung has expanded overseas, South Korea is still host to most of its factories and research engineers. \"\"\"\n","doc = nlp(text)\n","for ent in doc.ents:\n","    print(ent.text, ent.start_char, ent.end_char, ent.label_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UrN2p3M5Cuy1","outputId":"a14c17ac-14ad-413b-da48-8a0e58dae858"},"outputs":[{"data":{"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"78212fd09b5741e68c358e853f645006-0\" class=\"displacy\" width=\"650\" height=\"212.0\" direction=\"ltr\" style=\"max-width: none; height: 212.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"122.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"122.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">love</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"122.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">you,</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">PRON</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"122.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">Juliet.</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">PROPN</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-78212fd09b5741e68c358e853f645006-0-0\" stroke-width=\"2px\" d=\"M70,77.0 C70,2.0 200.0,2.0 200.0,77.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-78212fd09b5741e68c358e853f645006-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,79.0 L62,67.0 78,67.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-78212fd09b5741e68c358e853f645006-0-1\" stroke-width=\"2px\" d=\"M220,77.0 C220,2.0 350.0,2.0 350.0,77.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-78212fd09b5741e68c358e853f645006-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M350.0,79.0 L358.0,67.0 342.0,67.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-78212fd09b5741e68c358e853f645006-0-2\" stroke-width=\"2px\" d=\"M370,77.0 C370,2.0 500.0,2.0 500.0,77.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-78212fd09b5741e68c358e853f645006-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M500.0,79.0 L508.0,67.0 492.0,67.0\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I love you, \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Juliet\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",".</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import spacy\n","from spacy import displacy\n","text1 = 'I love you, Juliet.'\n","\n","nlp=spacy.load('en_core_web_md')   # NLTK에서는 dependency 그래프 그리기가 약간 더 복잡\n","displacy.render(nlp(text1),style='dep', jupyter=True, options ={'distance':150})\n","\n","displacy.render(nlp(text1),style=\"ent\",jupyter=True)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1sZUtbydCuy1"},"source":["### 참고: 한글 형태소분석 라이브러리 kiwipiepy  \n","https://github.com/bab2min/kiwipiepy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvlr4ABkCuy1","outputId":"bb06e2cf-69f4-4278-81ba-094f4e9d0ac3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Token(form='두', tag='MM', start=0, len=1), Token(form='개', tag='NNB', start=2, len=1), Token(form='의', tag='JKG', start=3, len=1), Token(form='문장', tag='NNG', start=5, len=2), Token(form='이', tag='JKS', start=7, len=1), Token(form='있', tag='VA', start=9, len=1), Token(form='어요', tag='EF', start=10, len=2), Token(form='.', tag='SF', start=12, len=1), Token(form='이런', tag='MM', start=14, len=2), Token(form='것', tag='NNB', start=17, len=1), Token(form='도', tag='JX', start=18, len=1), Token(form='분석', tag='NNG', start=20, len=2), Token(form='을', tag='JKO', start=22, len=1), Token(form='잘', tag='MAG', start=24, len=1), Token(form='하', tag='VV', start=26, len=1), Token(form='ᆯ까요', tag='EF', start=26, len=3), Token(form='?', tag='SF', start=29, len=1)]\n","[Sentence(text='두 개의 문장이 있어요.', start=0, end=13, tokens=None, subs=[]), Sentence(text='이런 것도 분석을 잘 할까요?', start=14, end=30, tokens=None, subs=[])]\n","두 개의 문장이 있어요. 이런 것도 분석을 잘 할까요?\n"]}],"source":["# pip install --upgrade pip\n","# pip install kiwipiepy\n","\n","# pip3 install --upgrade pip\n","# pip3 install kiwipiepy\n","\n","from kiwipiepy import Kiwi\n","from kiwipiepy.utils import Stopwords\n","\n","kiwi = Kiwi()\n","stopwords = Stopwords()\n","\n","# kiwi.add_user_word(word, tag, score, orig_word)\n","# kiwi.add_user_word('맛점', 'NNG', 0)\n","\n","# 사용자 사전 입력 성공 시 True, 실패 시 False 반환\n","# word : 등록할 형태소. 공백 문자를 포함하지 않은 문자열만 등록 가능.\n","# tag : 등록할 형태소의 품사. 기본값 NNP.\n","# score : 등록할 형태소의 점수. 동일한 형태로 분석될 가능성이 있는 경우 값이 클수록 해당 형태소가 더 우선권을 가지고 추출.\n","# orig_word : 추가할 형태소가 특정 형태소의 변형인 경우 이 인자로 원본 형태소를 넘겨줄 수 있고, 없는 경우 생략.\n","\n","# kiwi.extract_words(texts, min_cnt, max_word_len, min_score)\n","# kiwi.extract_add_words(texts, min_cnt, max_word_len, min_score, pos_score)\n","# texts : Iterable[str]\n","# min_cnt : 추출할 단어가 입력 텍스트 내에서 최소 몇 번 이상 등장하는 지 결정.\n","# max_word_len : 추출할 단어의 최대 길이.\n","# min_score : 추출할 단어의 최소 단어 점수.\n","# pos_socre : 추출할 단어의 최소 명사 점수.\n","\n","# kiwi.tokenize(text, match_option, normalize_coda=False)\n","# kiwi.tokenize(\"안 먹었엌ㅋㅋ\", normalize_coda=False)\n","# 결과 : [Token(form='안', tag='NNP', start=0, len=1),\n","#  Token(form='먹었엌', tag='NNP', start=2, len=3),\n","#  Token(form='ㅋㅋ', tag='SW', start=5, len=2)]\n","# normalize_coda : ㅋㅋㅋ, ㅎㅎㅎ와 같은 초성체가 뒤따라와 받침으로 들어가서 분석에 실패하는 문제를 해결.\n","# 덧붙은 받침 때문에 분석이 깨지는 경우를 방지\n","\n","# kiwi.tokenize(\"ㅋㅋㅋ 이런 것도 분석이 될까욬ㅋㅋ?\", normalize_coda=True)\n","\n","# add, remove 메소드를 이용해 불용어 목록에 단어를 추가하거나 삭제할 수도 있습니다.\n","# stopwords.add(('결과', 'NNG'))   # 분석 결과에서 '결과' 제외\n","# kiwi.tokenize(\"분석 결과에서 불용어만 제외하고 출력할 수도 있다.\", stopwords=stopwords)\n","\n","\n","# 입력된 텍스트를 형태소 분석하여 결과 반환. 총 top_n개의 결과로 출력\n","# kiwi.analyze(text, top_n, match_option, normalize_coda=False, z_coda=True, split_complex=False, blocklist=None)\n","\n","# 입력 텍스트를 문장 단위로 분할하여 반환.\n","# kiwi.split_into_sents(text, match_options=Match.ALL, normalize_coda=False, z_coda=True, split_complex=False, blocklist=None, return_tokens=False)\n","\n","# 여러 텍스트 조각을 문맥을 고려해 적절한 공백을 사이에 삽입하여 합침\n","# kiwi.glue(text_chunks, insert_new_lines=None, return_space_insertions=False)\n","\n","# 입력 텍스트에서 띄어쓰기 교정\n","# kiwi.space(text, reset_whitespace=False)\n","\n","# 형태소들을 결합하여 문장으로 복원\n","# kiwi.join(morphs, lm_search=True)\n","\n","print(kiwi.tokenize(\"두 개의 문장이 있어요. 이런 것도 분석을 잘 할까요?\", normalize_coda=False))\n","print(kiwi.split_into_sents(\"두 개의 문장이 있어요. 이런 것도 분석을 잘 할까요?\"))\n","print(kiwi.space(\"두개의문장이있어요.이런것도 분석을잘할까요?\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tCTjawGSCuy2","outputId":"8fa333f1-ff58-48ea-b837-2a25e3e41ef5"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Token(form='오늘', tag='NNG', start=0, len=2), Token(form='은', tag='JX', start=2, len=1), Token(form='정말', tag='MAG', start=4, len=2), Token(form='맛', tag='NNG', start=7, len=1), Token(form='점', tag='NNG', start=8, len=1), Token(form='하', tag='XSV', start=9, len=1), Token(form='고', tag='EC', start=10, len=1), Token(form='싶', tag='VX', start=12, len=1), Token(form='다', tag='EF', start=13, len=1), Token(form='.', tag='SF', start=14, len=1)]\n"]}],"source":["print(kiwi.tokenize(\"오늘은 정말 맛점하고 싶다.\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LfbqZkfCuy2","outputId":"14d68b6f-d523-4248-aa61-5e70abb497c4"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["kiwi.add_user_word('맛점', 'NNG', 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-OxFDy6yCuy2","outputId":"c70f6b93-28f6-4c20-e661-2222cd109156"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Token(form='오늘', tag='NNG', start=0, len=2), Token(form='은', tag='JX', start=2, len=1), Token(form='정말', tag='MAG', start=4, len=2), Token(form='맛점', tag='NNG', start=7, len=2), Token(form='하', tag='XSV', start=9, len=1), Token(form='고', tag='EC', start=10, len=1), Token(form='싶', tag='VX', start=12, len=1), Token(form='다', tag='EF', start=13, len=1), Token(form='.', tag='SF', start=14, len=1)]\n"]}],"source":["print(kiwi.tokenize(\"오늘은 정말 맛점하고 싶다.\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vt4N6qTRCuy2"},"outputs":[],"source":["# pip3 install kiwipiepy\n","from kiwipiepy import Kiwi\n","from kiwipiepy.utils import Stopwords\n","import pandas as pd\n","\n","kiwi = Kiwi()\n","stopwords = Stopwords()\n","\n","# new_words = pd.read_csv('new_words.csv')\n","# for new_word in new_words[\"Column1\"]:\n","#     kiwi.add_user_word(new_word, 'NNG', 0)\n","\n","new_words = ['고령화', '고령사회', '액티브시니어', '파워시니어', '실버세대', '실버칼라', '크리에이터']\n","\n","for new_word in new_words:\n","    kiwi.add_user_word(new_word, 'NNG', 0)\n","\n","stopwords_list = ['이번', '최근', '최초', '어제', '올해', '내년', '지난해', '오후', '이날', '오늘', '처음', '이후']\n","\n","for stop_word in stopwords_list:\n","    stopwords.add((stop_word, 'NNG'))\n","\n","\n","def extract_noun(text):\n","    tokens = [\n","        token.form\n","        for token in kiwi.tokenize(text)\n","        if token.tag in ['NNG', 'NNP'] and len(token.form)>1 and token.form not in stopwords_list\n","    ]\n","    tokens= [x.replace('AI', '인공지능').replace('ai', '인공지능') for x in tokens]\n","    return tokens\n","\n","norm_list = [('인공 지능', '인공지능'), ('독거 노인', '독거노인'),\n","             ('자살율', '자살률'), ('취업율', '취업률'), ('진학율', '진학률')]\n","\n","def norm_text(text):\n","    for n in norm_list:\n","        text=text.replace(n[0], n[1])\n","    return text"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}