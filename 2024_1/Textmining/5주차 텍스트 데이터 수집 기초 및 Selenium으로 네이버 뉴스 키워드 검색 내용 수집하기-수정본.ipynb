{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집 기초 및 Selenium으로 네이버 뉴스 키워드 검색 내용 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 정적/동적 웹 페이지\n",
    "* 정적 웹 페이지: 웹 서버(Web Server)에 미리 저장된 파일이 한 번에 전달되는 웹 페이지, URL만으로 수집 가능, BeautifulSoup과 requests 또는 Selenium 또는 Selenium과 BeautifulSoup 사용  \n",
    "* 동적 웹 페이지: URL 만으로는 수집하기 어려운 웹 페이지, URL의 변화가 없는데도 실시간으로 내용이 계속해서 추가되거나 수정된다면 동적 웹 페이지, Selenium 또는 Selenium과 BeautifulSoup 사용\n",
    "    - 로그인을 해야만 접속 가능한 네이버 메일\n",
    "    - 드래그를 아래로 내리면 계속 새로운 사진과 영상이 나타나는 인스타그램과 유튜브"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 수집 지원 라이브러리\n",
    "* requests: 특정 URL로부터 HTML 문서를 가져오는 작업을 수행  \n",
    "\n",
    "* BeautifulSoup: 가져온 HTML 문서를 Soup 객체로 만들어 원하는 HTML 태그를 추출할 수 있도록 지원하는 라이브러리 \n",
    "\n",
    "* Selenium: BeautifulSoup은 자바스크립트(Java Script)로 동적으로 생성된 정보는 가져올 수 없음 - 스크래핑이 의외로 안 되는 대부분의 경우 자바스크립트로 HTML을 작성했기 때문, 정적/동적 웹 페이지 모두에 사용 가능, 컴퓨터에 설치되어 있는 웹 브라우저를 자동으로 구동해주는 라이브러리, 크롬 브라우저 이용 권장 \n",
    "    - 자동으로 로그인하기, 메일보내기 자동화, 블로그 이웃 새글 자동 좋아요 누르기, 인스타그램 자동으로 좋아요 댓글 작성하기 등에 활용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 기타 데이터 수집 방법  \n",
    "* 데이터 수집 솔루션 및 Automatio, Octoparse 등 코딩 없이 워크플로우 설정만으로 크롤링 지원하는 유료 툴 사용\n",
    "* 공공데이터포털(https://www.data.go.kr/), 국립국어원 모두의 말뭉치(https://corpus.korean.go.kr/request/reausetMain.do) 등 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selenium 활용 기초  \n",
    "* 메뉴얼: https://www.selenium.dev/documentation/webdriver/elements/finders/\n",
    "* 데이터 수집 대상 사이트: https://www.example.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium 설치\n",
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/html/body/div/p[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 크롬 드라이버 실행 파일 다운로드  \n",
    "**`Windows`**  \n",
    "1. 내 컴퓨터의 크롬 버전 확인: 크롬을 실행한 후 오른쪽 위에 점 3개 &rightarrow; 도움말 &rightarrow; Chrome 정보 선택  \n",
    "2. https://chromedriver.chromium.org/downloads 에서 내 컴퓨터의 크롬 버전과 동일한 버전의 드라이버 다운로드  \n",
    ">2024년 4월 현재 최신 크롬 드라이버 버전이 114, 최신 크롬은 123 버전이라 이전 크롬을 삭제하고, 크롬도 114 버전으로 통일하여 설치  \n",
    ">크롤링 기간 동안 크롬과 윈도우 자동 업데이트 해제 필요(검색=>msconfig=>시스템구성=>서비스=>하단 모든 MS 서비스 숨기기 체크=>Google 업데이트 서비스 2가지 해제, 설정=>윈도우업데이트)  \n",
    "3. 다운로드 받은 크롬 드라이버 압축 해제 후 chromedriver.exe 파일을 현재 노트북 파일 위치로 이동 또는 드라이버 패스 정보 카피 - 예시(C:\\Users\\user\\Downloads\\chromedriver_win32)\n",
    "    \n",
    "**`MacOS`**  \n",
    "1. 터미널에서 homebrew를 이용하여 아래 명령어로 chromedriver 설치(brew 설치 방법 참고 https://brew.sh/index_ko)    \n",
    "    brew install chromedriver  \n",
    "2. 개발자 확인 오류가 뜨면, 아래 명령어 실행 &rightarrow; 폴더 버전 확인(버전 91.0.4472.19 이라고 가정) &rightarrow; 폴더 안으로 이동 &rightarrow; xattr 명령어 실행    \n",
    "    cd /usr/local/Caskroom/chromedriver/  \n",
    "    ls  \n",
    "    cd 91.0.4472.19  \n",
    "    xattr -d com.apple.quarantine chromedriver   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "# driver = webdriver.Chrome(\"chromedriver file path\")\n",
    "# driver = webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\")\n",
    "\n",
    "# Get HTML source of the target site\n",
    "driver.get(\"https://www.example.com\")\n",
    "\n",
    "# Wait for page loading for 3 seconds\n",
    "driver.implicitly_wait(time_to_wait = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "\n",
      "\n",
      "</body></html>\n"
     ]
    }
   ],
   "source": [
    "# 정적인 웹페이지인 경우 다음과 같이 html 소스를 저장해서 분석 가능\n",
    "page_html = driver.page_source\n",
    "print(page_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1_tag.text: Example Domain\n",
      "----------------------------------------------------------------------------------------------------\n",
      "p_tag.text: This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "p_tag.text: More information...\n",
      "More information...\n",
      "More information...\n"
     ]
    }
   ],
   "source": [
    "# Get the first element with tag name 'div'\n",
    "element = driver.find_element(By.TAG_NAME, 'div')\n",
    "h1_tag = element.find_element(By.TAG_NAME, 'h1')\n",
    "print(f\"h1_tag.text: {h1_tag.text}\")\n",
    "\n",
    "# Get all the elements available with tag name 'p'\n",
    "elements = element.find_elements(By.TAG_NAME, 'p')\n",
    "for e in elements:\n",
    "    print(\"-\"*100)\n",
    "    print(f\"p_tag.text: {e.text}\")\n",
    "\n",
    "print(driver.find_element(By.LINK_TEXT, \"More information...\").text)\n",
    "print(driver.find_element(By.CSS_SELECTOR,\"[href='https://www.iana.org/domains/example']\").text) \n",
    "# 속성값을 함께 나타낼 때 [] 사용\n",
    "# CSS(Cascading Style Sheets)는 HTML과 같은 마크업언어로 작성된 웹페이지의 글꼴, 색상, 크기 등 스타일과 레이아웃 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 특정 element를 가져오는 명령어 예시\n",
    "driver.find_element(By.XPATH, '//button[text()=\"Some text\"]')   \n",
    "driver.find_element(By.ID, 'loginForm')  \n",
    "driver.find_element(By.LINK_TEXT, 'Continue')  \n",
    "driver.find_element(By.PARTIAL_LINK_TEXT, 'Conti')  \n",
    "driver.find_element(By.NAME, 'username')  \n",
    "driver.find_element(By.TAG_NAME, 'h1')  \n",
    "driver.find_element(By.CLASS_NAME, 'content')  \n",
    "driver.find_element(By.CSS_SELECTOR, 'p.content')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.\n"
     ]
    }
   ],
   "source": [
    "# F12 개발자도구 => 해당 부분(뉴스 탭) 클릭 => 마우스 오른쪽 버튼 => Copy => Copy XPath \n",
    "first_p_tag = driver.find_element(By.XPATH, '/html/body/div/p[1]')\n",
    "print(first_p_tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More information...\n",
      "https://www.iana.org/domains/example\n"
     ]
    }
   ],
   "source": [
    "second_p_tag = driver.find_element(By.XPATH, '/html/body/div/p[2]')\n",
    "print(second_p_tag.text)\n",
    "a_tag = second_p_tag.find_element(By.TAG_NAME, 'a')\n",
    "href = a_tag.get_attribute('href')\n",
    "print(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 본 셀 내용은 실행하지 말고 보세요~\n",
    "\n",
    "<ol id=\"vegetables\">\n",
    " <li class=\"potatoes\">…\n",
    " <li class=\"onions\">…\n",
    " <li class=\"tomatoes\"><span>Tomato is a Vegetable</span>…\n",
    "</ol>\n",
    "<ul id=\"fruits\">\n",
    "  <li class=\"bananas\">…\n",
    "  <li class=\"apples\">…\n",
    "  <li class=\"tomatoes\"><span>Tomato is a Fruit</span>…\n",
    "</ul>\n",
    "\n",
    "# find_element로는 \"vegetables\" 안에 있는 \"tomatoes\" 만 추출됨\n",
    "vegetable = driver.find_element(By.CLASS_NAME, \"tomatoes\")\n",
    "\n",
    "# \"fruits\" 안에 있는 \"tomatoes\" 단계적으로 추출하기\n",
    "fruits = driver.find_element(By.ID, \"fruits\")\n",
    "fruit = fruits.find_element(By.CLASS_NAME,\"tomatoes\")\n",
    "\n",
    "# we can use either CSS or XPath to find this element in a single command\n",
    "# \"fruits\" 안에 있는 \"tomatoes\" CSS로 한 번에 추출하기\n",
    "fruit = driver.find_element(By.CSS_SELECTOR,\"#fruits .tomatoes\")  # => 앞에 아무것도 없으면 태그명, #id명 .클래스명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium으로 네이버 뉴스 키워드 검색 내용 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS 선택자\n",
    "\n",
    "예시: #content > div.cover-masonry > div > ul > li:nth-child(1) > a > span.thum > img  \n",
    "먼저, #content는 id가 \"content\"인 요소(또는 태그)를 선택  \n",
    "그리고 >는 자식 요소를 선택하는 연산자  \n",
    "div.cover-masonry는 \"cover-masonry\"라는 클래스를 가진 div 요소를 선택  \n",
    "ul은 unordered list 요소를 선택  \n",
    "li:nth-child(1)는 첫 번째 list item 요소를 선택  \n",
    "a는 anchor 요소를 선택  \n",
    "span.thum은 \"thum\"이라는 클래스를 가진 span 요소를 선택\n",
    "img는 image 요소를 선택  \n",
    "\n",
    "따라서 이 선택자는 id가 \"content\"인 요소의 자식 중 \"cover-masonry\"라는 클래스를 가진 div 요소의 자식 중 ul 요소의 자식 중 첫 번째 li 요소의 자식 중 a 요소의 자식 중 \"thum\"이라는 클래스를 가진 span 요소의 자식 중 img 요소를 선택\n",
    "\n",
    "웹 크롤링에서는 이러한 CSS 선택자를 사용하여 웹 페이지의 특정 요소를 선택하고 그 내용을 추출  \n",
    "이 선택자는 BeautifulSoup나 Selenium과 같은 라이브러리에서 사용  \n",
    "이 라이브러리들은 CSS 선택자를 사용하여 웹 페이지의 요소를 선택하고, \n",
    "그 요소의 텍스트, 속성 등을 추출하는 기능을 제공  \n",
    "이를 통해 웹 크롤러는 웹 페이지의 특정 부분의 데이터만을 선택적으로 수집 가능  \n",
    "\n",
    "## XPATH \n",
    "- 마크업 언어에서 특정 요소를 찾기 위한 경로(path)를 나타냄  \n",
    "- F12 개발자도구 => 해당 부분(뉴스 탭) 클릭 => 마우스 오른쪽 버튼 => Copy => Copy XPath \n",
    "\n",
    "'//' : 최상위 루트  \n",
    "'*' : 자손 태그 - 바로밑에 밑에 있는 태그  \n",
    "'/' : 자식 태그 - 바로 밑에 속해 있는 태그  \n",
    "'div[1]' : div 중에서 1번째 태그  \n",
    "\n",
    "##### XPATH 읽어보기  \n",
    "//*[@id=\"main_pack\"]/section[2]/div/div[2]/panel-list/div/ul/li[1]/div/div/a]  \n",
    "최상위 루트에서 시작해서 자손태그중에 아이디가 main_pack이 있고  \n",
    "바로 밑에 selection의 2번째 태그가 있고 그 바로 밑에 div태그가 있고 그 바로 밑에 div2번째 태그가 있고  \n",
    "그 바로 밑에 panel-list태그가 있고 ...  \n",
    "\n",
    "## 스크롤바 활용 방법 기초\n",
    "document의 body부분에서 scroll의 길이를 반환한다  \n",
    "driver.execute_script('return document.body.scrollHeight')  \n",
    "\n",
    "화면 스크롤 상단 이동  \n",
    "driver.execute_script('window.scrollTo(0,0);')  \n",
    "\n",
    "화면 스크롤 하단 이동  \n",
    "driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium beautifulsoup4 webdriver_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크롬드라이버 수동 설치(구버전, skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비트코인 7% 이상 급락, 6만5000달러도 붕괴(상보)\n",
      "\"18일 뒤 2억 설\" 반감기 앞둔 비트코인, 지금 들어갈까?\n",
      "비트코인 5.61% 급락, 6만6000달러 붕괴\n",
      "비트코인, 9600만원선 뚝…이더러움·리플 등 롤러코스터\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Media</th>\n",
       "      <th>Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>비트코인 7% 이상 급락, 6만5000달러도 붕괴(상보)</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>박형기 기자</td>\n",
       "      <td>이 시각 현재 주요 암호화폐 시황 - 코인마켓캡 갈무리(서울=뉴스1) 박형기 기자 ...</td>\n",
       "      <td>2024.04.02. 오후 10:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"18일 뒤 2억 설\" 반감기 앞둔 비트코인, 지금 들어갈까?</td>\n",
       "      <td>주간조선</td>\n",
       "      <td>김혜인 기자</td>\n",
       "      <td>photo 게티이미지코리아호재로 꼽히는 비트코인 반감기가 18일 앞으로 다가온 가운...</td>\n",
       "      <td>2024.04.02. 오전 3:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>비트코인 5.61% 급락, 6만6000달러 붕괴</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>None</td>\n",
       "      <td>[서울=뉴시스] 김진아 기자 = 암호화폐거래소 FTX가 파산보호 신청 직후 일부 자...</td>\n",
       "      <td>2024.04.02. 오후 9:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>비트코인, 9600만원선 뚝…이더러움·리플 등 롤러코스터</td>\n",
       "      <td>더팩트</td>\n",
       "      <td>이중삼 기자</td>\n",
       "      <td>반감기 앞두고 매수·매도 줄다리기\\n\\n\\n\\n비트코인이 급락하며 9600만원선까지...</td>\n",
       "      <td>2024.04.02. 오후 2:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title Media    Name  \\\n",
       "0     비트코인 7% 이상 급락, 6만5000달러도 붕괴(상보)   뉴스1  박형기 기자   \n",
       "1  \"18일 뒤 2억 설\" 반감기 앞둔 비트코인, 지금 들어갈까?  주간조선  김혜인 기자   \n",
       "2          비트코인 5.61% 급락, 6만6000달러 붕괴   뉴시스    None   \n",
       "3     비트코인, 9600만원선 뚝…이더러움·리플 등 롤러코스터   더팩트  이중삼 기자   \n",
       "\n",
       "                                             Content                  Time  \n",
       "0  이 시각 현재 주요 암호화폐 시황 - 코인마켓캡 갈무리(서울=뉴스1) 박형기 기자 ...  2024.04.02. 오후 10:42  \n",
       "1  photo 게티이미지코리아호재로 꼽히는 비트코인 반감기가 18일 앞으로 다가온 가운...   2024.04.02. 오전 3:01  \n",
       "2  [서울=뉴시스] 김진아 기자 = 암호화폐거래소 FTX가 파산보호 신청 직후 일부 자...   2024.04.02. 오후 9:21  \n",
       "3  반감기 앞두고 매수·매도 줄다리기\\n\\n\\n\\n비트코인이 급락하며 9600만원선까지...   2024.04.02. 오후 2:34  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def crawl_naver_news(keyword, start_date, end_date):\n",
    "    base_url = \"https://search.naver.com/search.naver?where=news&query={}&pd=3&ds={}&de={}\"\n",
    "    \n",
    "    # 날짜 형식을 YYYY.MM.DD로 변환\n",
    "    start_date_str = start_date.strftime('%Y.%m.%d')\n",
    "    end_date_str = end_date.strftime('%Y.%m.%d')\n",
    "    \n",
    "    # URL 생성\n",
    "    url = base_url.format(keyword, start_date_str, end_date_str)\n",
    "    \n",
    "    # 웹드라이버 설정\n",
    "#     driver = webdriver.Chrome('path/to/chromedriver')  # chromedriver의 경로를 지정해주세요.\n",
    "    driver = webdriver.Chrome()   # 크롬 드라이버가 현재워킹디렉토리에 있을 때\n",
    "    \n",
    "    # 웹사이트 접속\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    k = 1\n",
    "    data = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while k < 20:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "        naver_news_view_path = f'//*[@id=\"sp_nws{k}\"]/div[1]/div/div[1]/div[2]/a[2]'  \n",
    "        # 기사 리스트 페이지의 각 기사 항목에 있는 네이버뉴스 보기 XPath \n",
    "#         //*[@id=\"sp_nws1\"]/div[1]/div/div[1]/div[2]/a[2]\n",
    "#         //*[@id=\"sp_nws6\"]/div[1]/div/div[1]/div[2]/a[2]\n",
    "#         //*[@id=\"sp_nws11\"]/div[1]/div/div[1]/div[2]/a[2]\n",
    "#         //*[@id=\"sp_nws16\"]/div/div/div[1]/div[2]/a[2]\n",
    "\n",
    "        try:\n",
    "            naver_news_view = driver.find_element(By.XPATH, naver_news_view_path)\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "\n",
    "        naver_news_view.click()    # 사람이 해당 뉴스의 네이버뉴스 클릭하는 것과 비슷\n",
    "        time.sleep(2)\n",
    "\n",
    "        driver.switch_to.window(driver.window_handles[1])  \n",
    "        # driver.window_handles[]: 프로세스상 열려있는 윈도우 리턴, 번호는 0부터 시작, 1은 두번째 윈도우\n",
    "        # driver.switch_to: 지정한 윈도우를 활성화시킴\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        response = driver.page_source\n",
    "        one_page = BeautifulSoup(response)\n",
    "   \n",
    "        # Selenium 방법 예시:        title_elem = driver.find_element(By.XPATH, '//*[@id=\"title_area\"]/span')\n",
    "        # BeautifulSoup 방법 예시:   title = title_elem.text if title_elem else None\n",
    "\n",
    "        # title_elem = one_page.find('div', class_='media_end_head_title')\n",
    "        # html에서 태그 이름이 div이면서(<div ) class 값이 'media_end_head_title' 인 첫번째 태그 찾기\n",
    "        # CSS 선택자는 id와 class 속성을 위한 특수 문법 #과 .이 있음\n",
    "        # 유일하게 속성 중 class는 class_로 써 줘야, 파이썬에서 class는 클래스를 만드는데 사용되는 예약어이므로\n",
    "\n",
    "        title_elem = one_page.find('div', class_='media_end_head_title')\n",
    "        if title_elem is None:\n",
    "            print(f\"num: {num},  k: {k}\")\n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "            continue  # 포맷이 다른 스포츠 기사가 발견 되어 추가, 스포츠 외에 TV 연예 면도 형식 다름 \n",
    "        title = title_elem.text.strip() if title_elem else None\n",
    "        print(title)\n",
    "\n",
    "        media_elem = one_page.find('img', class_='media_end_head_top_logo_img light_type _LAZY_LOADING _LAZY_LOADING_INIT_HIDE')\n",
    "        media = media_elem['alt'] if media_elem else None   \n",
    "\n",
    "        name_elem = one_page.find('em', class_='media_end_head_journalist_name')\n",
    "        name = name_elem.text if name_elem else None\n",
    "\n",
    "        content_elem = one_page.find('article', class_='go_trans _article_content')  # 2차 크롤링에서 태그 이름이 바뀜\n",
    "        content = content_elem.text.strip() if content_elem else None   # 하위 태그에 있는 텍스트들도 수집됨\n",
    "\n",
    "        time_elem = one_page.find('span', class_='media_end_head_info_datestamp_time _ARTICLE_DATE_TIME')\n",
    "        timestamp = time_elem.text if time_elem else None\n",
    "\n",
    "        data.append([title, media, name, content, timestamp])\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        k += 5\n",
    "    \n",
    "     # 웹드라이버 종료\n",
    "#     driver.quit()\n",
    "\n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame(data, columns=['Title', 'Media', 'Name', 'Content', 'Time'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 키워드와 기간 설정\n",
    "keyword = \"비트코인\"\n",
    "start_date = datetime.datetime(2024, 4, 2)\n",
    "end_date = datetime.datetime(2024, 4, 2)\n",
    "\n",
    "# 크롤링 실행\n",
    "df = crawl_naver_news(keyword, start_date, end_date)\n",
    "\n",
    "df.to_csv(\"비트코인_네이버_기사_\" + str(start_date)[:10] + \"-\" + str(end_date)[:10] + \".csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 데이터프레임 출력\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크롬드라이버 자동 설치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 326, 'y': 630}\n",
      "630\n",
      "{'x': 362, 'y': 803}\n",
      "803\n",
      "네이버뉴스 보기 간격: 173\n",
      "nws1 found\n",
      "하버드 의대 교수 “의사보다 나은 AI? 100% 진료 시기상조”\n",
      "nws2 found\n",
      "[천자칼럼] 스타게이트 프로젝트\n",
      "nws3 found\n",
      "중장년의 ‘리스타트’… 대구시가 응원합니다\n",
      "nws4 found\n",
      "[사설] 다시 온 반도체 호황, 이 기회 놓치면 한국 반도체 쇠락할 것\n",
      "nws5 found\n",
      "[여현덕의 AI Thinking] 오픈AI와 스타트업 앤스로픽의 ‘AI 이데아’ 경쟁\n",
      "nws6 found\n",
      "\"카드사 'AI 전환' 관건 데이터 활용에 달렸다\"\n",
      "nws7 found\n",
      "[목멱칼럼]'친절한 새 이웃' AI를 기대하며\n",
      "nws8 found\n",
      "샘 올트먼, '오픈AI 스타트업 펀드' 운영서 손 뗀다\n",
      "nws9 found\n",
      "동원그룹, 자체 AI 플랫폼 '동원GPT' 도입\n",
      "nws10 found\n",
      "동원그룹 자체 AI플랫폼 GPT로 업무생산성 향상\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Media</th>\n",
       "      <th>Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>하버드 의대 교수 “의사보다 나은 AI? 100% 진료 시기상조”</td>\n",
       "      <td>중앙일보</td>\n",
       "      <td>김형구 기자</td>\n",
       "      <td>로버트 슈멀링           ‘의사 도움 없이 전적으로 인공지능(AI) 진료에 ...</td>\n",
       "      <td>2024.04.02. 오전 12:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[천자칼럼] 스타게이트 프로젝트</td>\n",
       "      <td>한국경제</td>\n",
       "      <td>None</td>\n",
       "      <td>공상과학(SF)영화의 기념비적 걸작 ‘2001 스페이스 오디세이’(1968년 개봉)...</td>\n",
       "      <td>2024.04.02. 오전 12:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>중장년의 ‘리스타트’… 대구시가 응원합니다</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>명민준 기자</td>\n",
       "      <td>상담부터 정착까지 전 과정 지원취업하면 장려금 80만 원 지급대구시는 실직 위기에 ...</td>\n",
       "      <td>2024.04.02. 오전 3:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[사설] 다시 온 반도체 호황, 이 기회 놓치면 한국 반도체 쇠락할 것</td>\n",
       "      <td>조선일보</td>\n",
       "      <td>None</td>\n",
       "      <td>윤석열 대통령과 조 바이든 미국 대통령이 2022년 5월 경기 평택 삼성전자 반도체...</td>\n",
       "      <td>2024.04.02. 오전 3:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[여현덕의 AI Thinking] 오픈AI와 스타트업 앤스로픽의 ‘AI 이데아’ 경쟁</td>\n",
       "      <td>국민일보</td>\n",
       "      <td>None</td>\n",
       "      <td>헌법 정신 가르친 AI ‘클로드3’ 부상소수 연구자 세상 흔드는 것 보여줘AI 춘추...</td>\n",
       "      <td>2024.04.02. 오전 4:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"카드사 'AI 전환' 관건 데이터 활용에 달렸다\"</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>정병묵 기자</td>\n",
       "      <td>[금융인라운지]하나카드 최고데이터책임자 최병정 상무통계학 박사로 IT SW 업체 S...</td>\n",
       "      <td>2024.04.02. 오전 5:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[목멱칼럼]'친절한 새 이웃' AI를 기대하며</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>None</td>\n",
       "      <td>하민회 이미지21 대표\\n\\n\\n\\n[하민회 이미지21 대표]“ 나 꽤 잘한 것 같...</td>\n",
       "      <td>2024.04.02. 오전 6:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>샘 올트먼, '오픈AI 스타트업 펀드' 운영서 손 뗀다</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>전선형 기자</td>\n",
       "      <td>지난달 29일 지배구조 변경 신고파트너인 이언 해서웨이가 지배[이데일리 전선형 기자...</td>\n",
       "      <td>2024.04.02. 오전 7:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>동원그룹, 자체 AI 플랫폼 '동원GPT' 도입</td>\n",
       "      <td>전자신문</td>\n",
       "      <td>강성전 기자</td>\n",
       "      <td>동원그룹 임직원이 동원GPT 실습 교육을 받고 있다.동원그룹은 자체 인공지능(AI)...</td>\n",
       "      <td>2024.04.02. 오전 8:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>동원그룹 자체 AI플랫폼 GPT로 업무생산성 향상</td>\n",
       "      <td>디지털타임스</td>\n",
       "      <td>이상현 기자</td>\n",
       "      <td>동원그룹은 자체 인공지능(AI) 플랫폼 '동원GPT'를 도입해 업무에 활용하고 있다...</td>\n",
       "      <td>2024.04.02. 오전 10:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title   Media    Name  \\\n",
       "0             하버드 의대 교수 “의사보다 나은 AI? 100% 진료 시기상조”    중앙일보  김형구 기자   \n",
       "1                                [천자칼럼] 스타게이트 프로젝트    한국경제    None   \n",
       "2                          중장년의 ‘리스타트’… 대구시가 응원합니다    동아일보  명민준 기자   \n",
       "3          [사설] 다시 온 반도체 호황, 이 기회 놓치면 한국 반도체 쇠락할 것    조선일보    None   \n",
       "4  [여현덕의 AI Thinking] 오픈AI와 스타트업 앤스로픽의 ‘AI 이데아’ 경쟁    국민일보    None   \n",
       "5                     \"카드사 'AI 전환' 관건 데이터 활용에 달렸다\"    이데일리  정병묵 기자   \n",
       "6                        [목멱칼럼]'친절한 새 이웃' AI를 기대하며    이데일리    None   \n",
       "7                   샘 올트먼, '오픈AI 스타트업 펀드' 운영서 손 뗀다    이데일리  전선형 기자   \n",
       "8                       동원그룹, 자체 AI 플랫폼 '동원GPT' 도입    전자신문  강성전 기자   \n",
       "9                      동원그룹 자체 AI플랫폼 GPT로 업무생산성 향상  디지털타임스  이상현 기자   \n",
       "\n",
       "                                             Content                  Time  \n",
       "0  로버트 슈멀링           ‘의사 도움 없이 전적으로 인공지능(AI) 진료에 ...  2024.04.02. 오전 12:10  \n",
       "1  공상과학(SF)영화의 기념비적 걸작 ‘2001 스페이스 오디세이’(1968년 개봉)...  2024.04.02. 오전 12:29  \n",
       "2  상담부터 정착까지 전 과정 지원취업하면 장려금 80만 원 지급대구시는 실직 위기에 ...   2024.04.02. 오전 3:06  \n",
       "3  윤석열 대통령과 조 바이든 미국 대통령이 2022년 5월 경기 평택 삼성전자 반도체...   2024.04.02. 오전 3:27  \n",
       "4  헌법 정신 가르친 AI ‘클로드3’ 부상소수 연구자 세상 흔드는 것 보여줘AI 춘추...   2024.04.02. 오전 4:08  \n",
       "5  [금융인라운지]하나카드 최고데이터책임자 최병정 상무통계학 박사로 IT SW 업체 S...   2024.04.02. 오전 5:16  \n",
       "6  하민회 이미지21 대표\\n\\n\\n\\n[하민회 이미지21 대표]“ 나 꽤 잘한 것 같...   2024.04.02. 오전 6:16  \n",
       "7  지난달 29일 지배구조 변경 신고파트너인 이언 해서웨이가 지배[이데일리 전선형 기자...   2024.04.02. 오전 7:42  \n",
       "8  동원그룹 임직원이 동원GPT 실습 교육을 받고 있다.동원그룹은 자체 인공지능(AI)...   2024.04.02. 오전 8:27  \n",
       "9  동원그룹은 자체 인공지능(AI) 플랫폼 '동원GPT'를 도입해 업무에 활용하고 있다...  2024.04.02. 오전 10:12  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "# 크롬드라이버 생성\n",
    "options = Options()\n",
    "options.add_argument('--start-maximized')  # 브라우저 구동 화면 최대화\n",
    "service = Service(ChromeDriverManager().install())  \n",
    "driver = webdriver.Chrome(service=service, options=options)  # 시스템에 적합한 크롬드라이버 자동 설치 \n",
    "\n",
    "# 크롤링 키워드와 기간 설정\n",
    "keyword = \"챗GPT\"\n",
    "start_date = datetime.datetime(2024, 4, 2)\n",
    "end_date = datetime.datetime(2024, 4, 2)\n",
    "\n",
    "# 네이버기사 사이트 URL에 크롤링 키워드와 기간 넣어 타겟 URL 생성\n",
    "# base_url = \"https:/search.naver.com/search.naver?where=news&query={}&pd=3&ds={}&de={}\"  # 이렇게하면 네이버뉴스 보기가 없는 뉴스도 포함됨\n",
    "\n",
    "# https://search.naver.com/search.naver?where=news&query=%EC%B1%97GPT&sm=tab_opt&sort=2&photo=3&field=0&pd=3&ds=2024.04.02&de=2024.04.02&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom20240402to20240402&is_sug_officeid=0&office_category=0&service_area=0\n",
    "base_url = \"https://search.naver.com/search.naver?where=news&query={}&sm=tab_opt&sort=2&photo=3&field=0&pd=3&ds={}&de={}&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom20240402to20240402&is_sug_officeid=0&office_category=0&service_area=0\"\n",
    "\n",
    "start_date_str = start_date.strftime('%Y.%m.%d')  # 날짜 형식을 YYYY.MM.DD로 변환\n",
    "end_date_str = end_date.strftime('%Y.%m.%d')  # 날짜 형식을 YYYY.MM.DD로 변환\n",
    "url = base_url.format(keyword, start_date_str, end_date_str)  # URL 생성\n",
    "\n",
    "# 타겟 URL 접속\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "# 첫번째 두번째 뉴스의 네이버보기 Y좌표 간격 확인\n",
    "naver_news_view1_path = f'//*[@id=\"sp_nws1\"]/div[1]/div/div[1]/div[2]/a[2]'  \n",
    "naver_news_view1 = driver.find_element(By.XPATH, naver_news_view1_path)\n",
    "print(naver_news_view1.location)\n",
    "print(naver_news_view1.location['y'])\n",
    "naver_news_view1_y_value = naver_news_view1.location['y']\n",
    "\n",
    "naver_news_view2_path = f'//*[@id=\"sp_nws2\"]/div[1]/div/div[1]/div[2]/a[2]'  \n",
    "naver_news_view2 = driver.find_element(By.XPATH, naver_news_view2_path)\n",
    "print(naver_news_view2.location)\n",
    "print(naver_news_view2.location['y'])\n",
    "naver_news_view2_y_value = naver_news_view2.location['y']\n",
    "\n",
    "print(f\"네이버뉴스 보기 간격: {naver_news_view2_y_value-naver_news_view1_y_value}\")\n",
    "interval = naver_news_view2_y_value-naver_news_view1_y_value\n",
    "\n",
    "# 스크롤바를 적당한 위치로 이동\n",
    "# 모니터에 보여야 selenium으로 클릭할 수 있음, Y좌표는 가져올 수 있어도 모니터에 보이지 않아 클릭이 안되는 경우 있음\n",
    "driver.execute_script(f'window.scrollTo(0, {naver_news_view1_y_value-150})') \n",
    "# driver.execute_script(f'window.scrollTo(0, {naver_news_view1_y_valu})')  # 이 위치로 가면 첫번째 네이버뉴스 보기가 보이지 않음\n",
    "current_y_value = naver_news_view1_y_value-150\n",
    "\n",
    "# 네이버뉴스 보기를 순서대로 클릭하면서 해당 기사를 크롤링\n",
    "news_num = 10   # 크롤링할 뉴스 갯수\n",
    "k = 1\n",
    "\n",
    "data = []\n",
    "while k <= news_num:\n",
    "\n",
    "    naver_news_view_path = f'//*[@id=\"sp_nws{k}\"]/div[1]/div/div[1]/div[2]/a[2]'  \n",
    "    # 기사 리스트 페이지의 각 기사 항목에 있는 네이버뉴스 보기 XPath \n",
    "#         //*[@id=\"sp_nws1\"]/div[1]/div/div[1]/div[2]/a[2]\n",
    "#         //*[@id=\"sp_nws2\"]/div[1]/div/div[1]/div[2]/a[2]\n",
    "#         //*[@id=\"sp_nws3\"]/div[1]/div/div[1]/div[2]/a[2]\n",
    "\n",
    "    try:\n",
    "        naver_news_view = driver.find_element(By.XPATH, naver_news_view_path)\n",
    "        print(f\"nws{k} found\")\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "    \n",
    "    naver_news_view.click()    # 사람이 해당 뉴스의 네이버뉴스 클릭하는 것과 비슷\n",
    "    time.sleep(2)\n",
    "\n",
    "    driver.switch_to.window(driver.window_handles[1])  \n",
    "    # driver.window_handles[]: 프로세스상 열려있는 윈도우 리턴, 번호는 0부터 시작, 1은 두번째 윈도우\n",
    "    # driver.switch_to: 지정한 윈도우를 활성화시킴\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    response = driver.page_source\n",
    "    one_page = BeautifulSoup(response)\n",
    "\n",
    "    # Selenium 방법 예시:        title_elem = driver.find_element(By.XPATH, '//*[@id=\"title_area\"]/span')\n",
    "    # BeautifulSoup 방법 예시:   title = title_elem.text if title_elem else None\n",
    "\n",
    "    # title_elem = one_page.find('div', class_='media_end_head_title')\n",
    "    # html에서 태그 이름이 div이면서(<div ) class 값이 'media_end_head_title' 인 첫번째 태그 찾기\n",
    "    # CSS 선택자는 id와 class 속성을 위한 특수 문법 #과 .이 있음\n",
    "    # 유일하게 속성 중 class는 class_로 써 줘야, 파이썬에서 class는 클래스를 만드는데 사용되는 예약어이므로\n",
    "\n",
    "    title_elem = one_page.find('div', class_='media_end_head_title')\n",
    "    if title_elem is None:\n",
    "        print(f\"num: {num},  k: {k}\")\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        continue  # 포맷이 다른 스포츠 기사가 발견 되어 추가, 스포츠 외에 TV 연예 면도 형식 다름 \n",
    "    title = title_elem.text.strip() if title_elem else None\n",
    "    print(title)\n",
    "\n",
    "    media_elem = one_page.find('img', class_='media_end_head_top_logo_img light_type _LAZY_LOADING _LAZY_LOADING_INIT_HIDE')\n",
    "    media = media_elem['alt'] if media_elem else None   \n",
    "\n",
    "    name_elem = one_page.find('em', class_='media_end_head_journalist_name')\n",
    "    name = name_elem.text if name_elem else None\n",
    "\n",
    "    content_elem = one_page.find('article', class_='go_trans _article_content')  # 2차 크롤링에서 태그 이름이 바뀜\n",
    "    content = content_elem.text.strip() if content_elem else None   # 하위 태그에 있는 텍스트들도 수집됨\n",
    "\n",
    "    time_elem = one_page.find('span', class_='media_end_head_info_datestamp_time _ARTICLE_DATE_TIME')\n",
    "    timestamp = time_elem.text if time_elem else None\n",
    "\n",
    "    data.append([title, media, name, content, timestamp])\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    current_y_value += interval  # current_y_value = current_y_value+interval\n",
    "    driver.execute_script(f'window.scrollTo(0, {current_y_value})') \n",
    "    k += 1\n",
    "\n",
    "# 웹드라이버 종료\n",
    "# driver.quit()\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(data, columns=['Title', 'Media', 'Name', 'Content', 'Time'])\n",
    "df.to_csv(keyword + \"_\" + str(start_date)[:10] + \"-\" + str(end_date)[:10] + \".csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 데이터프레임 출력\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-02 00:00:00\t<class 'datetime.datetime'>\n",
      "2024-04-02 00:00:00\t2024-04-02\n"
     ]
    }
   ],
   "source": [
    "print(start_date, type(start_date), sep='\\t')\n",
    "print(str(start_date), str(start_date)[:10], sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
